{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8325518a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_ENABLE_ONEDNN_OPTS=0\n"
     ]
    }
   ],
   "source": [
    "%env TF_ENABLE_ONEDNN_OPTS 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f7ec64-69af-4cc9-884c-f61023d07132",
   "metadata": {
    "executionInfo": {
     "elapsed": 2863,
     "status": "ok",
     "timestamp": 1666274947208,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "75f7ec64-69af-4cc9-884c-f61023d07132",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c70190e4-1903-41ed-8897-040f6808a020",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666274947208,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "c70190e4-1903-41ed-8897-040f6808a020",
    "outputId": "248fa78f-5e9d-4db2-d134-2762d69323b5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HRKbR8ZA9tIu",
   "metadata": {
    "id": "HRKbR8ZA9tIu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# DSA5205 Project\n",
    "\n",
    "Ref:\n",
    "- [AlphaNet：因子挖掘神经网络 - 华泰证券](https://crm.htsc.com.cn/doc/2020/10750101/74856806-a2e3-41cb-be4c-695dc6cc1341.pdf)\n",
    "- [再探AlphaNet：结构和特征优化 - 华泰证券](https://crm.htsc.com.cn/doc/2020/10750101/74619658-f648-4001-a255-5b78174b073a.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b9f103-0a81-4cc1-8e8c-226d40f546cf",
   "metadata": {
    "id": "31b9f103-0a81-4cc1-8e8c-226d40f546cf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. calculation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe3037f-3941-4da6-87ff-c5fffc8ac6de",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274947208,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "8fe3037f-3941-4da6-87ff-c5fffc8ac6de",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#combination c^2_N\n",
    "def generate(N):\n",
    "    col = []\n",
    "    col_rev = []\n",
    "    for i in range(1,N):\n",
    "        for j in range(0,i):\n",
    "            col.append([i,j])\n",
    "    return col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98797082-b05f-4949-97e3-02b52bb03d79",
   "metadata": {
    "id": "98797082-b05f-4949-97e3-02b52bb03d79",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51408d77-3d75-4d0c-b64e-850a12d322e1",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274947208,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "51408d77-3d75-4d0c-b64e-850a12d322e1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ts_corr(Matrix,stride):\n",
    "#Matrix: tensorflow(none, 9, 30)\n",
    "    W = Matrix.shape[2]\n",
    "    H = Matrix.shape[1]\n",
    "    num=generate(H)\n",
    "    if W % stride == 0:\n",
    "        Index_list = list(np.arange(0,W+stride,stride))\n",
    "    else:\n",
    "        mod = W % stride\n",
    "        Index_list = list(np.arange(0,W+stride-mod,stride)) + [W]\n",
    "    l = []\n",
    "    for i in range(len(Index_list)-1):\n",
    "        start_index = Index_list[i]\n",
    "        end_index = Index_list[i+1]\n",
    "        #N*len(num)*2*stride\n",
    "        data1 = tf.gather(Matrix,axis=1,indices=num)[:,:,:,start_index:end_index]\n",
    "        mean1 = tf.reduce_mean(data1, axis=-1)\n",
    "        spread1 = data1 - tf.expand_dims(mean1, axis=-1)\n",
    "        #N*len(num)*2*1\n",
    "        std=(tf.reduce_sum(spread1*spread1,axis=-1, keepdims=True)/(spread1.shape[-1]-1))**0.5\n",
    "        #N*len(num)*1\n",
    "        cov=tf.reduce_sum(tf.reduce_prod(spread1, axis=-2), axis=-1, keepdims=True)/(data1.shape[-1]-1)\n",
    "        corr=cov/tf.reduce_prod(std,axis=-2)\n",
    "\n",
    "        l.append(corr)\n",
    "\n",
    "    return tf.concat(l,axis=-1) #N*len(num)*[W/H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36f42aa7-a80f-44fe-9186-fbb2f9f21b1b",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274947208,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "36f42aa7-a80f-44fe-9186-fbb2f9f21b1b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ts_cov(Matrix,stride):\n",
    "#Matrix: tensorflow(none, 9, 30)\n",
    "    W = Matrix.shape[2]\n",
    "    H = Matrix.shape[1]\n",
    "    num=generate(H)\n",
    "    if W % stride == 0:\n",
    "        Index_list = list(np.arange(0,W+stride,stride))\n",
    "    else:\n",
    "        mod = W % stride\n",
    "        Index_list = list(np.arange(0,W+stride-mod,stride)) + [W]\n",
    "    l = []\n",
    "    for i in range(len(Index_list)-1):\n",
    "        start_index = Index_list[i]\n",
    "        end_index = Index_list[i+1]\n",
    "        #N*len(num)*2*stride\n",
    "        data1 = tf.gather(Matrix,axis=1,indices=num)[:,:,:,start_index:end_index]\n",
    "        mean1 = tf.reduce_mean(data1, axis=-1)\n",
    "        spread1 = data1 - tf.expand_dims(mean1, axis=-1)\n",
    "        #N*len(num)*1\n",
    "        cov=tf.reduce_sum(tf.reduce_prod(spread1, axis=-2), axis=-1, keepdims=True)/(data1.shape[-1]-1)\n",
    "\n",
    "        l.append(cov)\n",
    "\n",
    "    return tf.concat(l,axis=-1) #N*len(num)*[W/H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "qI2v4XeD9qiK",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274947208,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "qI2v4XeD9qiK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ts_stdde(Matrix,stride):\n",
    "#Matrix: tensorflow(none, 9, 30)\n",
    "    W = Matrix.shape[2]\n",
    "\n",
    "    if W % stride == 0:\n",
    "        Index_list = list(np.arange(0,W+stride,stride))\n",
    "    else:\n",
    "        mod = W % stride\n",
    "        Index_list = list(np.arange(0,W+stride-mod,stride)) + [W]\n",
    "    l = []\n",
    "    for i in range(len(Index_list)-1):\n",
    "        start_index = Index_list[i]\n",
    "        end_index = Index_list[i+1]\n",
    "        #N*H*stride\n",
    "        data1 = Matrix[:,:,start_index:end_index]\n",
    "        mean1 = tf.reduce_mean(data1, axis=-1)\n",
    "        spread1 = data1 - tf.expand_dims(mean1, axis=-1)\n",
    "        #N*H*1\n",
    "        std=(tf.reduce_sum(spread1*spread1,axis=-1, keepdims=True)/(spread1.shape[-1]-1))**0.5\n",
    "\n",
    "        l.append(std)\n",
    "\n",
    "    return tf.concat(l,axis=-1) #N*H*[W/H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "LjC9Q6Wf9qiK",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274947209,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "LjC9Q6Wf9qiK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ts_zscore(Matrix,stride):\n",
    "#Matrix: tensorflow(none, 9, 30)\n",
    "    W = Matrix.shape[2]\n",
    "    if W % stride == 0:\n",
    "        Index_list = list(np.arange(0,W+stride,stride))\n",
    "    else:\n",
    "        mod = W % stride\n",
    "        Index_list = list(np.arange(0,W+stride-mod,stride)) + [W]\n",
    "    l = []\n",
    "    for i in range(len(Index_list)-1):\n",
    "        start_index = Index_list[i]\n",
    "        end_index = Index_list[i+1]\n",
    "        #N*H*stride\n",
    "        data1 = Matrix[:,:,start_index:end_index]\n",
    "        mean1 = tf.reduce_mean(data1, axis=-1)\n",
    "        spread1 = data1 - tf.expand_dims(mean1, axis=-1)\n",
    "        #N*H*1\n",
    "        std=(tf.reduce_sum(spread1*spread1,axis=-1, keepdims=True)/(spread1.shape[-1]-1))**0.5\n",
    "\n",
    "        l.append(tf.expand_dims(mean1, axis=-1)/std)\n",
    "\n",
    "    return tf.concat(l,axis=-1) #N*H*[W/H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1xqDKFSK9qiL",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274947209,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "1xqDKFSK9qiL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ts_return(Matrix,stride):\n",
    "#Matrix: tensorflow(none, 9, 30)\n",
    "    W = Matrix.shape[2]\n",
    "    if W % stride == 0:\n",
    "        Index_list = list(np.arange(0,W+stride,stride))\n",
    "    else:\n",
    "        mod = W % stride\n",
    "        Index_list = list(np.arange(0,W+stride-mod,stride)) + [W]\n",
    "    l = []\n",
    "    for i in range(len(Index_list)-1):\n",
    "        start_index = Index_list[i]\n",
    "        end_index = Index_list[i+1]\n",
    "        #N*H*1\n",
    "        data1 = Matrix[:,:,start_index:end_index]\n",
    "        return_ = (data1[:,:,-1]-data1[:,:,0])/(data1[:,:,0]+0.0001)-1\n",
    "        l.append(tf.expand_dims(return_, axis=-1))\n",
    "\n",
    "    return tf.concat(l,axis=-1) #N*H*[W/H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2CvdvxDV9qiL",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274947209,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "2CvdvxDV9qiL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ts_decaylinear(Matrix,stride):\n",
    "#Matrix: tensorflow(none, 9, 30)\n",
    "    W = Matrix.shape[2]\n",
    "    if W % stride == 0:\n",
    "        Index_list = list(np.arange(0,W+stride,stride))\n",
    "    else:\n",
    "        mod = W % stride\n",
    "        Index_list = list(np.arange(0,W+stride-mod,stride)) + [W]\n",
    "    l = []\n",
    "    for i in range(len(Index_list)-1):\n",
    "        start_index = Index_list[i]\n",
    "        end_index = Index_list[i+1]\n",
    "        #N*H*stride\n",
    "        data1 = Matrix[:,:,start_index:end_index]\n",
    "        range_ = end_index-start_index\n",
    "        weight = tf.range(1,range_+1,dtype=Matrix.dtype)\n",
    "        weight = weight/tf.reduce_sum(weight)\n",
    "        #N*H*1\n",
    "        wd = tf.reduce_sum(data1*weight, axis=-1, keepdims=True)\n",
    "        l.append(wd)\n",
    "\n",
    "    return tf.concat(l,axis=-1) #N*H*[W/H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "jpFyYUOZ9qiL",
   "metadata": {
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1666274948422,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "jpFyYUOZ9qiL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ts_min(Matrix,stride):\n",
    "#Matrix: tensorflow(none, 9, 30)\n",
    "    W = Matrix.shape[2]\n",
    "    if W % stride == 0:\n",
    "        Index_list = list(np.arange(0,W+stride,stride))\n",
    "    else:\n",
    "        mod = W % stride\n",
    "        Index_list = list(np.arange(0,W+stride-mod,stride)) + [W]\n",
    "    l = []\n",
    "    for i in range(len(Index_list)-1):\n",
    "        start_index = Index_list[i]\n",
    "        end_index = Index_list[i+1]\n",
    "        #N*H*stride\n",
    "        data1 = Matrix[:,:,start_index:end_index]\n",
    "        #N*H*1\n",
    "        l.append(tf.reduce_min(data1,axis=-1, keepdims=True))\n",
    "\n",
    "    return tf.concat(l,axis=-1) #N*H*[W/H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vLzWttfT9qiM",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666274948423,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "vLzWttfT9qiM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ts_max(Matrix,stride):\n",
    "#Matrix: tensorflow(none, 9, 30)\n",
    "    W = Matrix.shape[2]\n",
    "    if W % stride == 0:\n",
    "        Index_list = list(np.arange(0,W+stride,stride))\n",
    "    else:\n",
    "        mod = W % stride\n",
    "        Index_list = list(np.arange(0,W+stride-mod,stride)) + [W]\n",
    "    l = []\n",
    "    for i in range(len(Index_list)-1):\n",
    "        start_index = Index_list[i]\n",
    "        end_index = Index_list[i+1]\n",
    "        #N*H*stride\n",
    "        data1 = Matrix[:,:,start_index:end_index]\n",
    "        #N*H*1\n",
    "        l.append(tf.reduce_max(data1,axis=-1, keepdims=True))\n",
    "\n",
    "    return tf.concat(l,axis=-1) #N*H*[W/H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "Yq9APQKB9qiM",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666274948423,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "Yq9APQKB9qiM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ts_mean(Matrix,stride):\n",
    "#Matrix: tensorflow(none, 9, 30)\n",
    "    W = Matrix.shape[2]\n",
    "    if W % stride == 0:\n",
    "        Index_list = list(np.arange(0,W+stride,stride))\n",
    "    else:\n",
    "        mod = W % stride\n",
    "        Index_list = list(np.arange(0,W+stride-mod,stride)) + [W]\n",
    "    l = []\n",
    "    for i in range(len(Index_list)-1):\n",
    "        start_index = Index_list[i]\n",
    "        end_index = Index_list[i+1]\n",
    "        #N*H*stride\n",
    "        data1 = Matrix[:,:,start_index:end_index]\n",
    "        #N*H*1\n",
    "        l.append(tf.reduce_mean(data1,axis=-1, keepdims=True))\n",
    "\n",
    "    return tf.concat(l,axis=-1) #N*H*[W/H]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7lv5tBBV9qiM",
   "metadata": {
    "collapsed": false,
    "id": "7lv5tBBV9qiM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.1 check the output of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "HhoWAOWE9qiM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666274948424,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "HhoWAOWE9qiM",
    "outputId": "6da160ed-fa8c-4587-d707-ab10f73217b3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mean = [-10, 30]\n",
    "cov = [[10, 20], [20, 1000]]\n",
    "x, y = np.random.multivariate_normal(mean, cov, 5000).T\n",
    "plt.plot(x, y, 'x')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "JoMmFYsY9qiM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666274948424,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "JoMmFYsY9qiM",
    "outputId": "b5d36d87-2b96-4bde-fe86-690691e4d64f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2, 30000), dtype=float64, numpy=\narray([[[-15.75742135,  -4.17356137, -10.7663813 , ...,  -4.04914174,\n          -6.67246448,  -9.87295947],\n        [ 47.46242166,  52.59446766,  24.98364518, ...,  66.45530049,\n           3.56295759,   4.11905603]],\n\n       [[-10.76635892,  -7.52960061, -10.23906048, ..., -10.99098811,\n         -16.19719575,  -6.97066852],\n        [ 27.57098291,  58.74370421,  21.42311725, ...,   7.65747192,\n          44.97805404,  22.83737907]]])>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just for test, so the dimension may be different with real dataset\n",
    "testdata=tf.transpose(tf.constant(np.random.multivariate_normal(mean, cov, [2,30000])), perm=[0, 2, 1])\n",
    "testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "t8H8J8NO9qiN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274948424,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "t8H8J8NO9qiN",
    "outputId": "5d6386d6-18ed-486c-f977-991679db727f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 1, 3), dtype=float64, numpy=\narray([[[0.2115261 , 0.22022766, 0.20351491]],\n\n       [[0.19966508, 0.19659311, 0.21261218]]])>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#20/(10*1000)**0.5=0.2\n",
    "ts_corr(testdata,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "uLUulnfU9qiN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274948424,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "uLUulnfU9qiN",
    "outputId": "c1b41baa-7b62-4316-a424-a13316874fa0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 1, 3), dtype=float64, numpy=\narray([[[21.13518317, 22.34940007, 20.28222315]],\n\n       [[20.1287455 , 19.79609071, 21.22418054]]])>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#20\n",
    "ts_cov(testdata,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "VAZ3yh4e9qiN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1029,
     "status": "ok",
     "timestamp": 1666274949450,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "VAZ3yh4e9qiN",
    "outputId": "9d4936a3-bb78-46d5-8866-e12a539b00d1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2, 3), dtype=float64, numpy=\narray([[[ 3.14220683,  3.18325109,  3.13991592],\n        [31.79854743, 31.88035263, 31.73959004]],\n\n       [[ 3.20222085,  3.16102321,  3.13394592],\n        [31.48207165, 31.85542877, 31.85306972]]])>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_std=10**0.5 about 3.162;y_std=1000**0.5\n",
    "ts_stdde(testdata,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ntGpHdeF9qiN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666274949450,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "ntGpHdeF9qiN",
    "outputId": "7f121e5b-ddc3-427d-8bdb-da50436238a4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2, 3), dtype=float64, numpy=\narray([[[-3.16279708, -3.14830375, -3.1908615 ],\n        [ 0.95155547,  0.9382892 ,  0.94061304]],\n\n       [[-3.13059062, -3.14243386, -3.19795799],\n        [ 0.94528798,  0.95202051,  0.95077023]]])>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_mean/x_std=-10**0.5 ; y_mean/y_std=0.3*10**0.5\n",
    "ts_zscore(testdata,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "x0dSeqrb9qiN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666274949450,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "x0dSeqrb9qiN",
    "outputId": "96ce5bd7-f633-40fd-9d7b-11e14fa613f5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2, 3), dtype=float64, numpy=\narray([[[-1.34416765, -1.17652169, -1.10287402],\n        [ 0.1308571 ,  0.95868341, 25.77404509]],\n\n       [[-1.38017574, -0.51808264, -1.47018865],\n        [ 1.21130223, -1.53660849, -3.30270938]]])>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_return(testdata,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9GLIPEiU9qiN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274949450,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "9GLIPEiU9qiN",
    "outputId": "cf914e80-f84f-4241-849b-d87fe23fc25c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2, 3), dtype=float64, numpy=\narray([[[ -9.9493005 ,  -9.99250393, -10.0090058 ],\n        [ 30.10528315,  29.88294016,  29.96024052]],\n\n       [[-10.02038233,  -9.90232576, -10.03849449],\n        [ 30.0510547 ,  30.37508561,  30.35226855]]])>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_decaylinear(testdata,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "zTrKR_7-9qiO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666274949451,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "zTrKR_7-9qiO",
    "outputId": "cbe9b968-09dc-4293-a23f-6abc3f99efed",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2, 3), dtype=float64, numpy=\narray([[[ -20.77615783,  -25.33757427,  -21.82059827],\n        [ -99.68801961,  -95.74265617,  -97.83824352]],\n\n       [[ -21.88905825,  -22.24954393,  -22.42040972],\n        [-135.93250267, -115.78542852,  -96.19075795]]])>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_min(testdata,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "PtqAumv-9qiO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666274949451,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "PtqAumv-9qiO",
    "outputId": "4f980e54-4456-4f2a-e49d-3dad4e3b75cc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2, 3), dtype=float64, numpy=\narray([[[  2.15233175,   1.98559515,   2.50981615],\n        [148.42156481, 146.40681921, 156.03723365]],\n\n       [[  5.11975546,   2.65898499,   1.83252837],\n        [163.69574628, 144.18484646, 161.14819873]]])>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_max(testdata,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "lF7GJrp39qiO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274949451,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "lF7GJrp39qiO",
    "outputId": "41485dde-38d9-4730-e5ec-c0fc2cff7aa7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2, 3), dtype=float64, numpy=\narray([[[ -9.93816258, -10.02184136, -10.01903681],\n        [ 30.25808162,  29.91299043,  29.85467217]],\n\n       [[-10.02484255,  -9.93330638, -10.02222741],\n        [ 29.75962378,  30.32702153,  30.2849504 ]]])>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_mean(testdata,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gX7BY77z9qiO",
   "metadata": {
    "collapsed": false,
    "id": "gX7BY77z9qiO",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From the results above, the dimensions of outputs and statistics properties are right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PbUAsSs89qiO",
   "metadata": {
    "collapsed": false,
    "id": "PbUAsSs89qiO",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. block construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab53c7b3-b0a1-4404-ade6-1d3f51b3aac3",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274949451,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "ab53c7b3-b0a1-4404-ade6-1d3f51b3aac3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class alphanet_feature_Block(tf.keras.Model):\n",
    "    def __init__(self, stride):\n",
    "        super(alphanet_feature_Block, self).__init__(name='')\n",
    "        #stride: tensorflow/array(2,)\n",
    "        self.stride_feature, self.stride_pool = stride\n",
    "\n",
    "        #pooling layers\n",
    "        self.max_pool = tf.keras.layers.MaxPooling2D(pool_size=(1, 3),strides=(1, self.stride_pool), padding='valid')\n",
    "        self.mean_pool = tf.keras.layers.AveragePooling2D(pool_size=(1, 3),strides=(1, self.stride_pool), padding='valid')\n",
    "        #different in input and output\n",
    "        self.min_pool = tf.keras.layers.MaxPooling2D(pool_size=(1, 3),strides=(1, self.stride_pool), padding='valid')\n",
    "\n",
    "        #batchnormal for feature input\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn5 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn6 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn7 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        #batchnormal for pooling layer\n",
    "        self.bn1mean = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2mean = tf.keras.layers.BatchNormalization()\n",
    "        self.bn3mean = tf.keras.layers.BatchNormalization()\n",
    "        self.bn4mean = tf.keras.layers.BatchNormalization()\n",
    "        self.bn5mean = tf.keras.layers.BatchNormalization()\n",
    "        self.bn6mean = tf.keras.layers.BatchNormalization()\n",
    "        self.bn7mean = tf.keras.layers.BatchNormalization()\n",
    "        self.bn1max = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2max = tf.keras.layers.BatchNormalization()\n",
    "        self.bn3max = tf.keras.layers.BatchNormalization()\n",
    "        self.bn4max = tf.keras.layers.BatchNormalization()\n",
    "        self.bn5max = tf.keras.layers.BatchNormalization()\n",
    "        self.bn6max = tf.keras.layers.BatchNormalization()\n",
    "        self.bn7max = tf.keras.layers.BatchNormalization()\n",
    "        self.bn1min = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2min = tf.keras.layers.BatchNormalization()\n",
    "        self.bn3min = tf.keras.layers.BatchNormalization()\n",
    "        self.bn4min = tf.keras.layers.BatchNormalization()\n",
    "        self.bn5min = tf.keras.layers.BatchNormalization()\n",
    "        self.bn6min = tf.keras.layers.BatchNormalization()\n",
    "        self.bn7min = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "\n",
    "\n",
    "    #output: N*H*[W/H]*1, the last is the number of channel\n",
    "    def ts_corr(self, input_tensor, stride):\n",
    "        return tf.expand_dims(ts_corr(input_tensor, stride),axis=-1)\n",
    "\n",
    "\n",
    "    def ts_cov(self, input_tensor, stride):\n",
    "        return tf.expand_dims(ts_cov(input_tensor, stride),axis=-1)\n",
    "\n",
    "\n",
    "    def ts_stdde(self, input_tensor, stride):\n",
    "        return tf.expand_dims(ts_stdde(input_tensor, stride),axis=-1)\n",
    "\n",
    "\n",
    "    def ts_zscore(self, input_tensor, stride):\n",
    "        return tf.expand_dims(ts_zscore(input_tensor, stride),axis=-1)\n",
    "\n",
    "\n",
    "    def ts_return(self, input_tensor, stride):\n",
    "        return tf.expand_dims(ts_return(input_tensor, stride),axis=-1)\n",
    "\n",
    "\n",
    "    def ts_decaylinear(self, input_tensor, stride):\n",
    "        return tf.expand_dims(ts_decaylinear(input_tensor, stride),axis=-1)\n",
    "\n",
    "\n",
    "    #below functions could be replaced with pooling layers\n",
    "    def ts_min(self, input_tensor, stride):\n",
    "        return tf.expand_dims(ts_min(input_tensor, stride),axis=-1)\n",
    "\n",
    "\n",
    "    def ts_max(self, input_tensor, stride):\n",
    "        return tf.expand_dims(ts_max(input_tensor, stride),axis=-1)\n",
    "\n",
    "\n",
    "    def ts_mean(self, input_tensor, stride):\n",
    "        return tf.expand_dims(ts_mean(input_tensor, stride),axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        #input_tensor tensorflow:(N,9,30)\n",
    "        #feature layer\n",
    "        x1 = self.ts_corr(input_tensor,self.stride_feature)\n",
    "        x1 = self.bn1(x1, training=training)\n",
    "        x1f = tf.keras.layers.Flatten()(x1)\n",
    "\n",
    "        x2 = self.ts_cov(input_tensor,self.stride_feature)\n",
    "        x2 = self.bn2(x2, training=training)\n",
    "        x2f = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "        x3 = self.ts_stdde(input_tensor,self.stride_feature)\n",
    "        x3 = self.bn3(x3, training=training)\n",
    "        x3f = tf.keras.layers.Flatten()(x3)\n",
    "\n",
    "        x4 = self.ts_zscore(input_tensor,self.stride_feature)\n",
    "        x4 = self.bn4(x4, training=training)\n",
    "        x4f = tf.keras.layers.Flatten()(x4)\n",
    "\n",
    "        x5 = self.ts_return(input_tensor,self.stride_feature)\n",
    "        x5 = self.bn5(x5, training=training)\n",
    "        x5f = tf.keras.layers.Flatten()(x5)\n",
    "\n",
    "        x6 = self.ts_decaylinear(input_tensor,self.stride_feature)\n",
    "        x6 = self.bn6(x6, training=training)\n",
    "        x6f = tf.keras.layers.Flatten()(x6)\n",
    "\n",
    "        x7 = self.ts_mean(input_tensor,self.stride_feature)\n",
    "        x7 = self.bn7(x7, training=training)\n",
    "        x7f = tf.keras.layers.Flatten()(x7)\n",
    "\n",
    "        #feature output\n",
    "        feature_output = tf.concat([x1f, x2f, x3f, x4f, x5f, x6f, x7f],axis=-1)\n",
    "\n",
    "        #pooling layer\n",
    "        x1mean = self.mean_pool(x1)\n",
    "        x1mean = self.bn1mean(x1mean, training=training)\n",
    "        x1max = self.max_pool(x1)\n",
    "        x1max = self.bn1max(x1max, training=training)\n",
    "        x1min = -self.min_pool(-x1)\n",
    "        x1min = self.bn1min(x1min, training=training)\n",
    "        x1p = tf.concat([tf.keras.layers.Flatten()(x1mean),tf.keras.layers.Flatten()(x1max),tf.keras.layers.Flatten()(x1min)],axis=-1)\n",
    "\n",
    "        x2mean = self.mean_pool(x2)\n",
    "        x2mean = self.bn2mean(x2mean, training=training)\n",
    "        x2max = self.max_pool(x2)\n",
    "        x2max = self.bn2max(x2max, training=training)\n",
    "        x2min = -self.min_pool(-x2)\n",
    "        x2min = self.bn2min(x2min, training=training)\n",
    "        x2p = tf.concat([tf.keras.layers.Flatten()(x2mean),tf.keras.layers.Flatten()(x2max),tf.keras.layers.Flatten()(x2min)],axis=-1)\n",
    "\n",
    "        x3mean = self.mean_pool(x3)\n",
    "        x3mean = self.bn3mean(x3mean, training=training)\n",
    "        x3max = self.max_pool(x3)\n",
    "        x3max = self.bn3max(x3max, training=training)\n",
    "        x3min = -self.min_pool(-x3)\n",
    "        x3min = self.bn3min(x3min, training=training)\n",
    "        x3p = tf.concat([tf.keras.layers.Flatten()(x3mean),tf.keras.layers.Flatten()(x3max),tf.keras.layers.Flatten()(x3min)],axis=-1)\n",
    "\n",
    "        x4mean = self.mean_pool(x4)\n",
    "        x4mean = self.bn4mean(x4mean, training=training)\n",
    "        x4max = self.max_pool(x4)\n",
    "        x4max = self.bn4max(x4max, training=training)\n",
    "        x4min = -self.min_pool(-x4)\n",
    "        x4min = self.bn4min(x4min, training=training)\n",
    "        x4p = tf.concat([tf.keras.layers.Flatten()(x4mean),tf.keras.layers.Flatten()(x4max),tf.keras.layers.Flatten()(x4min)],axis=-1)\n",
    "\n",
    "        x5mean = self.mean_pool(x5)\n",
    "        x5mean = self.bn5mean(x5mean, training=training)\n",
    "        x5max = self.max_pool(x5)\n",
    "        x5max = self.bn5max(x5max, training=training)\n",
    "        x5min = -self.min_pool(-x5)\n",
    "        x5min = self.bn5min(x5min, training=training)\n",
    "        x5p = tf.concat([tf.keras.layers.Flatten()(x5mean),tf.keras.layers.Flatten()(x5max),tf.keras.layers.Flatten()(x5min)],axis=-1)\n",
    "\n",
    "        x6mean = self.mean_pool(x6)\n",
    "        x6mean = self.bn6mean(x6mean, training=training)\n",
    "        x6max = self.max_pool(x6)\n",
    "        x6max = self.bn6max(x6max, training=training)\n",
    "        x6min = -self.min_pool(-x6)\n",
    "        x6min = self.bn6min(x6min, training=training)\n",
    "        x6p = tf.concat([tf.keras.layers.Flatten()(x6mean),tf.keras.layers.Flatten()(x6max),tf.keras.layers.Flatten()(x6min)],axis=-1)\n",
    "\n",
    "        x7mean = self.mean_pool(x7)\n",
    "        x7mean = self.bn7mean(x7mean, training=training)\n",
    "        x7max = self.max_pool(x7)\n",
    "        x7max = self.bn7max(x7max, training=training)\n",
    "        x7min = -self.min_pool(-x7)\n",
    "        x7min = self.bn7min(x7min, training=training)\n",
    "        x7p = tf.concat([tf.keras.layers.Flatten()(x7mean),tf.keras.layers.Flatten()(x7max),tf.keras.layers.Flatten()(x7min)],axis=-1)\n",
    "\n",
    "        #pooling output\n",
    "        pooling_output = tf.concat([x1p,x2p,x3p,x4p,x5p,x6p,x7p],axis=-1)\n",
    "\n",
    "        #output\n",
    "        output = tf.concat([feature_output,pooling_output],axis=-1)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "G6q2NjOZ-tMl",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274949451,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "G6q2NjOZ-tMl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_AlphaNet(feature_block, input_shape=(9, 30), output_shape=10, name=\"AlphaNet\", dropout_seed=None, version=1):\n",
    "    r\"\"\"\n",
    "    Build AlphaNet model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_block: alphanet_feature_Block\n",
    "        Feature extraction model.\n",
    "    input_shape: int or tuple. optional, default=(9, 30)\n",
    "        Input data shape. (NOT include batch size)\n",
    "    output_shape: int, optional, default=10\n",
    "        Output data shape, i.e. the length of predicted days.\n",
    "    name: str, optional, default=\"AlphaNet\"\n",
    "        Model name.\n",
    "    dropout_seed: None or int, optional, default=None\n",
    "        Random seed in \"Dropout\" layer.\n",
    "    version: {1, 2, 3}, optional, default=1\n",
    "        Version of AlphaNet. Details can be found in papers. Not supported for 2/3.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model: tf.keras.Model\n",
    "        AlphaNet model.\n",
    "    \"\"\"\n",
    "    # input\n",
    "    inputs = keras.layers.Input(shape=input_shape)\n",
    "    # feature layers\n",
    "    x = feature_block(inputs)\n",
    "    # the rest\n",
    "    init = keras.initializers.TruncatedNormal(mean=0., stddev=1.)\n",
    "    if version == 1:   # AlphaNet-v1\n",
    "        x = keras.layers.Dropout(rate=0.5, seed=dropout_seed, name=\"Dropout1\")(x)\n",
    "        #x = keras.layers.Dense(30, activation=\"relu\", kernel_initializer=init, name=\"Dense\")(x)\n",
    "        #sigmoid\n",
    "        x = keras.layers.Dense(512, activation=\"sigmoid\", kernel_initializer=keras.initializers.TruncatedNormal(mean=0., stddev=1.), name=\"Dense1\")(x)\n",
    "        x = keras.layers.Dense(256, activation=\"sigmoid\", kernel_initializer=keras.initializers.TruncatedNormal(mean=0., stddev=1.), name=\"Dense2\")(x)\n",
    "        x = keras.layers.Dense(128, activation=\"sigmoid\", kernel_initializer=keras.initializers.TruncatedNormal(mean=0., stddev=1.), name=\"Dense3\")(x)\n",
    "        x = keras.layers.Dense(64, activation=\"sigmoid\", kernel_initializer=keras.initializers.TruncatedNormal(mean=0., stddev=1.), name=\"Dense4\")(x)\n",
    "        x = keras.layers.Dense(32, activation=\"sigmoid\", kernel_initializer=keras.initializers.TruncatedNormal(mean=0., stddev=1.), name=\"Dense5\")(x)\n",
    "    # elif version == 2:  # AlphaNet-v2\n",
    "    #     x = keras.layers.LSTM(30, activation=\"relu\", name=\"LSTM\")(x)\n",
    "    #     x = keras.layers.BatchNormalization(name=\"BN\")(x)\n",
    "    # elif version == 3:  # AlphaNet-v3\n",
    "    #     x = keras.layers.GRU(30, activation=\"relu\", name=\"GRU\")(x)\n",
    "    #     x = keras.layers.BatchNormalization(name=\"BN\")(x)\n",
    "    outputs = keras.layers.Dense(output_shape, activation=\"linear\", kernel_initializer=init, name=\"Output\")(x)\n",
    "\n",
    "    # create model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=name) \n",
    "\n",
    "    # complie setting\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    # if version == 1:\n",
    "    #     optimizer = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "    # else:\n",
    "    #     optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    loss = keras.losses.MeanSquaredError()\n",
    "    metrics = [keras.metrics.MeanSquaredError(name=\"MSE\")]\n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "    # return\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cyfLh4DI-5it",
   "metadata": {
    "id": "cyfLh4DI-5it",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aoZ-Hz8g9qiP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274949451,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "aoZ-Hz8g9qiP",
    "outputId": "03faa590-37e4-446b-be63-f8ae14f77f75",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([100, 9, 30])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.arange(1,10)\n",
    "cov = np.eye(9)*[2,3,6,7,2,9,3,5,3]\n",
    "testdata2 = tf.transpose(tf.constant(np.random.multivariate_normal(mean, cov, [100,30])), perm=[0, 2, 1])\n",
    "testdata2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1abu7ZcF9qiP",
   "metadata": {
    "executionInfo": {
     "elapsed": 4013,
     "status": "ok",
     "timestamp": 1666274953461,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "1abu7ZcF9qiP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "testb_feature = alphanet_feature_Block([10,3])\n",
    "testb = build_AlphaNet(testb_feature, dropout_seed=123, version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3WS8Pv9s9qiP",
   "metadata": {
    "executionInfo": {
     "elapsed": 1358,
     "status": "ok",
     "timestamp": 1666274954817,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "3WS8Pv9s9qiP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modelb = testb(testdata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "PyAXAuSu9qiP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666274954818,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "PyAXAuSu9qiP",
    "outputId": "e5ef364c-5d18-4b21-f42b-6b930af187f3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(100, 10), dtype=float32, numpy=\narray([[-6.5306664e+00,  1.8586098e+00,  3.5126410e+00,  1.4437835e+00,\n         2.3074940e-01, -2.9630988e+00,  7.3907018e-01, -1.7958735e+00,\n         6.4386350e-01,  3.5170426e+00],\n       [-6.2037020e+00,  1.8565565e+00,  3.6473076e+00,  4.8624989e-01,\n         9.1128391e-01, -2.8971231e+00,  2.9157782e-01, -1.6943736e+00,\n        -3.0003089e-01,  1.4384509e+00],\n       [-5.6760440e+00,  7.1939754e-01,  3.1726081e+00,  1.3600651e+00,\n        -3.0141807e-01, -3.4571893e+00, -1.6597413e-02, -2.3233354e+00,\n         3.8481051e-01,  2.6900864e+00],\n       [-6.4419460e+00,  1.9739674e+00,  3.1187932e+00,  7.3100233e-01,\n         2.8250217e-03, -3.4872067e+00,  4.0120971e-01, -1.4987869e+00,\n         1.0594699e+00,  3.4585960e+00],\n       [-5.3022666e+00,  2.6973128e-01,  2.9980726e+00,  2.7366006e+00,\n         1.6659704e+00, -3.6803391e+00, -6.6283327e-01, -2.9864724e+00,\n         6.6226870e-01,  1.2607015e+00],\n       [-5.0989451e+00,  1.2099093e+00,  1.9691763e+00,  2.8508728e+00,\n        -8.6517060e-01, -2.8556900e+00, -2.0782360e-01, -2.9013848e+00,\n        -1.1048286e+00,  3.2035923e+00],\n       [-6.3730736e+00,  1.7394533e+00,  3.7293024e+00,  1.5319449e+00,\n         1.0109838e-01, -1.8979452e+00, -3.4559762e-01, -2.2321329e+00,\n         2.6203066e-01, -6.4955437e-01],\n       [-5.9657607e+00,  1.0733801e+00,  3.2961686e+00,  1.2640585e+00,\n         1.1196502e+00, -2.5560544e+00, -6.8643439e-01, -1.5820460e+00,\n         1.7919987e+00,  2.3386917e+00],\n       [-6.3224683e+00,  1.6837682e+00,  4.1619887e+00,  1.6663796e-01,\n         3.7227750e-01, -2.2317953e+00, -1.9504912e-01, -1.3968621e+00,\n         5.1298177e-01,  5.4171646e-01],\n       [-5.9391127e+00,  1.4562618e+00,  3.1580172e+00, -8.8697332e-01,\n        -2.2455412e-01, -3.2407074e+00,  7.5222081e-01, -1.7062140e+00,\n        -2.1846869e+00,  2.8220487e+00],\n       [-6.9230075e+00,  1.3501829e+00,  2.2631490e+00,  1.4639143e+00,\n        -7.6123965e-01, -2.7174215e+00,  1.5773593e+00, -1.3314114e+00,\n         1.3930783e-01,  4.0262790e+00],\n       [-6.7095261e+00,  1.1304350e+00,  3.6321378e+00, -5.4296744e-01,\n         3.0536601e-01, -3.5150754e+00,  5.1709598e-01, -1.2798893e+00,\n        -7.3498487e-04,  3.1526554e+00],\n       [-6.1939049e+00,  1.5649529e+00,  3.1144679e+00,  7.2489566e-01,\n        -9.7826451e-02, -3.1720469e+00,  2.2690651e-01, -1.9884288e+00,\n         8.8343465e-01,  3.3478374e+00],\n       [-4.7513695e+00,  2.9383388e+00,  2.5885010e+00,  1.8887736e+00,\n         9.5768839e-01, -1.5173047e+00, -8.7945950e-01, -1.9992658e+00,\n        -3.7226778e-01,  1.6372508e+00],\n       [-5.5534558e+00,  1.9241549e+00,  2.9169054e+00,  7.3609143e-01,\n         5.4231769e-01, -3.2755251e+00, -7.1110338e-01, -1.6108538e+00,\n         1.0596725e-01,  3.1591763e+00],\n       [-6.1649122e+00,  1.9089271e+00,  2.4586420e+00,  2.1378584e+00,\n         3.4816635e-01, -2.6308372e+00, -2.2266278e-01, -1.9504079e+00,\n         9.2280549e-01,  3.2032790e+00],\n       [-4.3861051e+00,  1.6146191e+00,  2.4345157e+00, -2.9341602e-01,\n         5.5287880e-01, -2.6146479e+00, -4.0498197e-02, -2.3871717e+00,\n        -9.7858554e-01,  1.3887216e+00],\n       [-5.0616112e+00,  4.3360239e-01,  2.3982661e+00,  1.2087375e+00,\n        -6.6132739e-02, -4.1295786e+00, -4.3114719e-01, -2.0017653e+00,\n         6.7203480e-01,  2.7890522e+00],\n       [-6.0466547e+00,  1.8636125e+00,  3.7132075e+00, -4.6152878e-01,\n         8.7917423e-01, -4.0975966e+00,  5.0538605e-01, -1.5817444e+00,\n         1.3064686e+00,  3.4853439e+00],\n       [-5.5058274e+00,  2.0419829e+00,  2.9332411e+00,  1.7279195e+00,\n         5.6849545e-01, -3.6477489e+00,  2.0912558e-02, -1.4469752e+00,\n         2.3294389e-03,  2.6809886e+00],\n       [-2.8905594e+00,  2.0178986e+00,  1.3919567e+00,  1.3106364e+00,\n         1.1123883e+00, -2.8889136e+00, -1.4880366e+00, -2.9935417e+00,\n        -1.0695686e+00,  1.3882132e+00],\n       [-5.8569202e+00,  1.4866024e+00,  3.0359819e+00,  3.4855247e-01,\n         2.6387191e-01, -3.1959665e+00, -2.0545174e-01, -2.0978036e+00,\n         1.0863347e-01,  1.2608155e+00],\n       [-4.3302855e+00,  1.8148733e+00,  2.1205420e+00,  4.2598635e-01,\n         7.6787853e-01, -3.0305130e+00, -1.1699077e+00, -2.3773148e+00,\n        -6.8229264e-01,  1.6631751e+00],\n       [-3.4172370e+00,  2.0961022e+00,  2.2591066e+00,  1.0452242e+00,\n         1.2393562e-01, -2.5844123e+00, -1.6105465e+00, -3.1254644e+00,\n        -1.7199336e+00,  1.0866985e+00],\n       [-5.8171673e+00,  1.8957361e+00,  3.8443322e+00,  8.8564575e-02,\n         1.9419390e+00, -2.1238606e+00,  2.5306198e-01, -2.1461871e+00,\n        -3.1414768e-01, -7.4207497e-01],\n       [-5.6915212e+00,  2.3638031e+00,  3.9931846e+00,  9.8756099e-01,\n         4.1456458e-01, -1.8973264e+00, -5.8327919e-01, -2.2735703e+00,\n         1.1658098e+00,  2.4574783e-01],\n       [-5.4803505e+00,  1.4209977e+00,  3.7733500e+00,  1.1021793e+00,\n         1.6109221e-01, -2.9167638e+00, -1.1998068e+00, -2.5766675e+00,\n         3.1335703e-01,  6.7385203e-01],\n       [-4.5669117e+00,  1.5709635e+00,  1.5989116e+00,  1.7355185e+00,\n        -2.5691903e-01, -2.3802710e+00, -9.1911823e-01, -2.1298087e+00,\n        -7.4454254e-01,  2.7617176e+00],\n       [-4.3150587e+00,  2.2283766e+00,  3.0328317e+00,  9.4687384e-01,\n         1.4181805e+00, -2.6688042e+00, -1.7306691e+00, -2.5657494e+00,\n        -5.8202219e-01,  1.4717870e+00],\n       [-4.3172755e+00,  2.5994000e+00,  1.6807503e+00,  1.3432518e+00,\n         1.0806082e+00, -2.7867687e+00, -2.0098479e+00, -2.0297084e+00,\n        -5.3891337e-01,  2.2911332e+00],\n       [-5.9861436e+00,  2.0864561e+00,  4.3761687e+00,  5.2880496e-01,\n         8.7318069e-01, -2.8707197e+00,  5.5379605e-01, -1.8362674e+00,\n         1.3423018e-01,  2.1037610e+00],\n       [-6.6570587e+00,  2.6345915e-01,  4.6298399e+00, -1.6315308e+00,\n        -1.2536771e+00, -2.8661001e+00,  7.9464370e-01, -1.4867525e+00,\n        -2.5334466e+00,  1.5169380e+00],\n       [-6.1706495e+00,  1.0605361e+00,  3.3638232e+00,  1.0139071e+00,\n         1.9444373e-01, -3.7682195e+00,  1.2855667e+00, -2.0912516e+00,\n         5.6717783e-02,  3.8785143e+00],\n       [-5.7425251e+00,  2.6510057e+00,  3.2174544e+00,  2.1059921e+00,\n         1.3536270e+00, -2.2329621e+00, -1.2911665e+00, -1.9391648e+00,\n         1.7201486e+00,  2.9776378e+00],\n       [-4.4725575e+00,  1.5028859e+00,  1.8286898e+00,  2.8004019e+00,\n        -1.6865730e-02, -2.9845440e+00, -1.0865939e+00, -2.7958891e+00,\n        -2.4246264e-01,  2.6364851e+00],\n       [-5.4463587e+00,  2.7286019e+00,  3.6488383e+00,  1.2292585e+00,\n         3.8589653e-01, -1.8329091e+00, -1.8707118e+00, -2.5735881e+00,\n        -1.9971019e-01,  1.1192641e+00],\n       [-6.2505355e+00,  1.4354986e+00,  3.0743303e+00,  1.0312418e+00,\n        -8.0544353e-03, -2.9431353e+00,  6.7813838e-01, -1.7953736e+00,\n         1.2531334e+00,  4.1774163e+00],\n       [-6.1288042e+00,  6.6751707e-01,  2.5082045e+00,  1.6317904e+00,\n        -3.5870063e-01, -3.5739312e+00, -3.0441594e-01, -2.5133510e+00,\n         1.6346522e-01,  1.4060533e+00],\n       [-4.6399903e+00,  1.5419095e+00,  2.2075448e+00,  1.5364920e+00,\n         4.0194350e-01, -2.4825191e+00, -7.1760517e-01, -2.6401570e+00,\n        -8.5783607e-01,  1.7279080e+00],\n       [-6.1603041e+00,  1.0391318e+00,  2.4129400e+00,  1.2670108e+00,\n        -8.2975823e-01, -2.5386853e+00,  4.5494235e-01, -2.1547458e+00,\n         2.1213499e-01,  4.6609936e+00],\n       [-4.1458654e+00,  2.7266402e+00,  1.0757843e+00,  1.3372012e+00,\n         1.1111581e-01, -1.5513910e+00, -2.9077482e+00, -1.6816249e+00,\n         6.4761072e-02,  1.7076838e+00],\n       [-4.6427889e+00,  1.1724159e+00,  2.6435850e+00,  4.2916781e-01,\n         7.5561512e-01, -3.4457963e+00, -1.3475041e-01, -1.9902351e+00,\n         8.6613044e-02,  3.0473545e+00],\n       [-6.0730925e+00,  1.1779228e+00,  2.8467662e+00,  1.2153691e+00,\n         4.0868098e-01, -3.3792281e+00,  3.9603561e-03, -1.2599852e+00,\n         1.3217084e+00,  2.4090948e+00],\n       [-6.0435066e+00,  2.1898375e+00,  3.7770150e+00,  1.5572566e+00,\n         7.3130339e-02, -2.5735338e+00,  4.0673223e-01, -2.4715176e+00,\n         1.8444279e-01,  2.4329147e+00],\n       [-4.7676859e+00,  2.3109212e+00,  1.3016706e+00,  2.8957589e+00,\n        -1.9130650e-01, -2.5361948e+00, -9.7478491e-01, -1.8509668e+00,\n        -5.2993447e-01,  1.1899050e+00],\n       [-6.3944774e+00,  1.5056945e+00,  1.8487480e+00,  2.2031717e+00,\n         1.7473608e-02, -2.1776197e+00, -7.7401787e-01, -1.5983130e+00,\n         1.5078044e+00,  2.4399090e+00],\n       [-6.4957142e+00,  1.1891361e+00,  2.8675866e+00,  1.1141132e+00,\n        -4.5654878e-02, -2.6790028e+00,  5.0235236e-01, -1.7696064e+00,\n         1.0977948e+00,  3.9167032e+00],\n       [-6.6834073e+00,  1.5396247e+00,  2.4379513e+00,  2.7172337e+00,\n         9.7727105e-02, -2.0173070e+00,  8.3684251e-02, -2.3935988e+00,\n         1.1376112e+00,  1.3973018e+00],\n       [-6.2935448e+00,  3.2182422e+00,  3.8278408e+00,  8.6312133e-01,\n         5.9454846e-01, -2.4811914e+00, -8.3452225e-01, -2.3226676e+00,\n         1.2508332e+00,  2.9357114e+00],\n       [-6.5458264e+00,  1.4374113e+00,  4.3499894e+00,  6.1241972e-01,\n         5.0655007e-01, -3.2857313e+00,  2.8827205e-01, -2.1692386e+00,\n         1.5547720e+00,  2.5866587e+00],\n       [-5.5076551e+00,  1.1093227e+00,  3.3811865e+00,  1.0140274e+00,\n         9.2465812e-01, -3.5092142e+00, -3.6893564e-01, -1.7717588e+00,\n         1.7919662e+00,  1.7772462e+00],\n       [-5.4469318e+00,  1.7959203e+00,  2.6654625e+00,  1.9201860e+00,\n        -8.1133682e-01, -3.5149853e+00,  2.7440345e-01, -2.6727164e+00,\n        -1.0630593e+00,  3.2561381e+00],\n       [-6.3477578e+00,  6.9070661e-01,  2.9756467e+00,  6.5520525e-02,\n        -5.5102688e-01, -3.6954231e+00,  1.4883515e+00, -1.8629147e+00,\n        -4.7793362e-01,  4.4405088e+00],\n       [-5.7833695e+00,  1.2409104e+00,  3.9606028e+00,  4.7978830e-01,\n         9.4615108e-01, -3.9064801e+00, -5.6291711e-01, -1.7052189e+00,\n         1.1377375e+00,  2.5938492e+00],\n       [-6.4440985e+00,  2.0799174e+00,  3.1867731e+00,  1.0960176e+00,\n         5.0625020e-01, -2.6782379e+00, -2.7990377e-01, -2.0613079e+00,\n         5.6713825e-01,  2.4122252e+00],\n       [-6.0022817e+00,  1.3073217e+00,  3.0453544e+00,  6.1262912e-01,\n         1.1242248e-01, -2.2770126e+00,  5.4978091e-01, -2.0349629e+00,\n         5.3826797e-01,  4.0876184e+00],\n       [-5.6702538e+00,  9.5411795e-01,  3.0482345e+00,  1.4450409e+00,\n         9.1237044e-01, -3.1605170e+00, -1.0577763e+00, -2.2298834e+00,\n         1.7407116e+00,  1.3443025e+00],\n       [-7.0475411e+00,  5.3392738e-01,  3.1419125e+00,  1.2800084e+00,\n        -1.5057516e-01, -3.8763857e+00,  1.6440997e+00, -1.4251446e+00,\n        -3.0637449e-01,  2.8557522e+00],\n       [-5.0728245e+00,  1.0183425e+00,  3.3169734e+00, -3.8377988e-01,\n         6.3194358e-01, -3.4565413e+00, -1.2806985e-01, -1.5374198e+00,\n        -7.8582895e-01,  3.7993240e+00],\n       [-4.6916451e+00,  1.5400887e+00,  2.3308384e+00,  2.3875299e+00,\n        -7.5213188e-01, -3.3440106e+00,  7.5500846e-02, -2.9900842e+00,\n        -2.1614790e+00,  2.3123114e+00],\n       [-5.6253324e+00,  1.8078988e+00,  1.8355525e+00,  3.2994840e+00,\n         1.5176517e-01, -1.7297337e+00, -1.6478776e+00, -3.2416549e+00,\n         3.3536249e-01,  1.2805871e+00],\n       [-5.1339979e+00,  2.6166358e+00,  3.4902613e+00,  1.7697192e+00,\n         1.5568421e+00, -1.4846963e+00, -5.2058733e-01, -2.4490941e+00,\n        -7.6502156e-01,  1.1896937e+00],\n       [-6.4165668e+00,  9.5916903e-01,  2.2321301e+00,  2.0005736e+00,\n        -4.3027776e-01, -3.2664032e+00,  4.0785000e-01, -2.1668937e+00,\n         4.6830776e-01,  2.9381549e+00],\n       [-4.9918218e+00,  1.9678975e+00,  3.2179155e+00,  7.9204977e-01,\n         8.3075470e-01, -3.0974054e+00, -9.1705471e-01, -2.2794166e+00,\n        -9.9219352e-02,  2.0046384e+00],\n       [-4.3645720e+00,  2.3528991e+00,  2.3380775e+00,  1.8356479e+00,\n         2.9547688e-01, -1.5366899e+00, -1.1459912e+00, -3.3073108e+00,\n        -8.9882195e-01,  3.1589983e+00],\n       [-7.0550418e+00,  2.6089928e-01,  3.5065732e+00, -1.2071395e-01,\n        -2.6772901e-01, -3.4655743e+00,  1.1044836e+00, -1.5750945e+00,\n        -1.0038114e+00,  2.7184074e+00],\n       [-4.5931673e+00,  2.6776762e+00,  2.8380861e+00,  5.4917175e-01,\n         9.3558854e-01, -1.3589082e+00, -6.3288844e-01, -2.7974350e+00,\n        -5.5678743e-01,  3.0497005e+00],\n       [-4.6530719e+00,  2.3740561e+00,  2.6917145e+00,  9.3042946e-01,\n         8.7870920e-01, -2.0777473e+00, -1.4324354e+00, -2.4973629e+00,\n        -4.5944875e-01,  1.3561729e+00],\n       [-5.0961514e+00,  5.4326326e-01,  2.6652832e+00,  4.2549515e-01,\n         3.4937876e-01, -3.9916170e+00,  7.0575342e-02, -1.4729539e+00,\n        -4.2382789e-01,  4.0718760e+00],\n       [-5.3160043e+00,  2.4394267e+00,  2.1023936e+00,  7.5301939e-01,\n         7.5971842e-01, -2.4083183e+00, -7.9489690e-01, -1.4413300e+00,\n         5.9752554e-02,  2.0892122e+00],\n       [-5.8532953e+00,  1.4985904e+00,  3.5878940e+00,  1.5366745e-01,\n         9.7320855e-02, -4.0294304e+00,  1.4616366e-01, -2.0953140e+00,\n        -1.7473459e-01,  3.8390131e+00],\n       [-6.4848423e+00,  1.6871669e+00,  3.7714188e+00,  1.3219959e-01,\n         2.8863198e-01, -2.1795936e+00,  9.0094030e-01, -1.7442738e+00,\n        -7.7466774e-01, -4.0612677e-01],\n       [-6.7295380e+00,  1.9180132e+00,  3.1771474e+00,  7.8782725e-01,\n        -3.8525200e-01, -3.7556252e+00,  7.4495357e-01, -7.9090011e-01,\n         7.0478088e-01,  2.9174297e+00],\n       [-7.3274293e+00,  1.2014908e+00,  5.2022362e+00,  3.8615620e-01,\n         5.1067859e-01, -2.7225025e+00,  1.2713482e+00, -1.8593293e+00,\n         2.1233666e-01,  6.6189444e-01],\n       [-4.9435716e+00,  2.0573478e+00,  3.6972461e+00,  7.3711157e-01,\n         1.2884510e+00, -3.4969406e+00, -8.3744121e-01, -2.3571084e+00,\n        -5.6586939e-01,  1.7336863e+00],\n       [-4.3489199e+00,  1.9642596e+00,  1.6332504e+00,  1.8397677e+00,\n         8.3473861e-02, -2.6063528e+00, -5.8705580e-01, -2.5578265e+00,\n        -6.4154667e-01,  2.8498743e+00],\n       [-5.1761398e+00,  1.2965562e+00,  1.5598621e+00,  1.8709545e+00,\n         2.3553769e-01, -3.3991976e+00,  4.7376266e-01, -2.0280430e+00,\n         5.9992439e-01,  2.7318766e+00],\n       [-6.3063421e+00,  1.0668677e+00,  2.5171928e+00,  1.0680093e+00,\n        -2.6402572e-01, -3.9379330e+00,  7.3059547e-01, -1.5709713e+00,\n         4.9966034e-01,  3.6004555e+00],\n       [-4.8397217e+00,  5.8539385e-01,  3.0842092e+00,  7.9608393e-01,\n         4.0608051e-01, -3.3937507e+00, -4.7684196e-01, -2.2512178e+00,\n        -1.8366462e+00,  1.5752002e+00],\n       [-5.6615105e+00,  1.4888276e+00,  3.8647971e+00,  1.9336259e-01,\n         9.3209714e-01, -2.9405174e+00, -8.8911337e-01, -1.6881301e+00,\n         9.9227250e-01,  2.0084214e+00],\n       [-4.4599085e+00,  2.5664573e+00,  1.5418918e+00,  1.2713189e+00,\n         9.1969550e-01, -1.5251474e+00, -8.2832110e-01, -2.3060527e+00,\n         1.4870369e-01,  2.1072681e+00],\n       [-6.2195249e+00,  1.5281379e+00,  3.2848208e+00, -7.5364113e-04,\n         3.5887823e-01, -4.0081654e+00,  4.4567657e-01, -1.4416866e+00,\n         8.0773479e-01,  3.2219529e+00],\n       [-5.2717233e+00,  1.9231749e+00,  3.1393294e+00,  8.5029733e-01,\n         2.4493377e-01, -2.6278012e+00,  1.4898430e-01, -2.3848445e+00,\n        -1.0258522e+00,  3.7400310e+00],\n       [-6.0217710e+00,  7.8491914e-01,  2.7324400e+00,  1.8216282e-01,\n         5.6307435e-02, -3.6307144e+00,  1.2533092e+00, -1.1981742e+00,\n        -3.1732172e-01,  4.3309584e+00],\n       [-5.5181026e+00,  1.2608013e+00,  3.7098517e+00,  1.8923680e+00,\n         2.5112200e-01, -3.2309058e+00,  9.5360547e-02, -2.4313314e+00,\n        -8.1650800e-01,  2.0029552e+00],\n       [-5.9250383e+00,  6.9200557e-01,  3.2173765e+00,  4.3178725e-01,\n         1.3747894e+00, -2.5692499e+00,  2.7366042e-01, -1.6136698e+00,\n         1.8283725e+00,  1.2369896e+00],\n       [-6.3422961e+00,  1.3833305e+00,  2.7966080e+00,  1.3694873e+00,\n         5.7818407e-01, -2.5218451e+00,  2.1663594e-01, -1.9530376e+00,\n         1.0593466e+00,  1.7729815e+00],\n       [-5.1162848e+00,  1.7390194e+00,  3.3397863e+00,  1.3782440e+00,\n         1.0437459e+00, -2.9289238e+00, -9.0187663e-01, -2.1479146e+00,\n         5.1657152e-01,  1.7336801e+00],\n       [-6.6000772e+00,  1.6060783e+00,  4.0261450e+00,  1.6512939e+00,\n         4.5831752e-01, -1.8622953e+00, -5.3556722e-01, -2.4821382e+00,\n         6.2246758e-01,  5.7109702e-01],\n       [-5.6218824e+00,  1.6422403e+00,  3.1028659e+00,  7.9777437e-01,\n         7.4862051e-01, -2.4975646e+00, -5.0552148e-01, -1.6432943e+00,\n         1.2063684e+00,  3.2035923e+00],\n       [-5.2716937e+00,  2.6641502e+00,  3.4889734e+00,  1.3841943e+00,\n         1.4399004e+00, -2.3086557e+00, -1.6531712e+00, -2.6453583e+00,\n         2.8901976e-01,  1.5142286e+00],\n       [-5.9632406e+00,  2.3060064e+00,  2.9575241e+00,  5.2526587e-01,\n         1.3201959e+00, -2.8264177e+00,  1.1957016e-02, -1.5639348e+00,\n         4.8363379e-01,  1.2993605e+00],\n       [-5.3406487e+00,  1.7443870e+00,  2.9494097e+00, -3.4280676e-01,\n         9.5470965e-01, -3.7112951e+00, -1.9988281e-01, -1.4806545e+00,\n        -5.5654794e-03,  2.2334046e+00],\n       [-5.1122055e+00,  1.6766359e+00,  2.9915967e+00,  8.1468076e-01,\n         1.0777296e+00, -3.7262199e+00, -7.2520763e-01, -1.9188128e+00,\n         3.1474039e-02,  1.6331873e+00],\n       [-4.1829157e+00,  2.5691597e+00,  2.3381667e+00, -1.3340360e-01,\n         2.9917911e-01, -1.6335042e+00, -2.4459225e-01, -2.6847975e+00,\n        -1.8481876e+00,  1.3410411e+00],\n       [-5.0406365e+00,  1.5045861e+00,  3.3532290e+00,  5.0337571e-01,\n         1.3255434e+00, -3.5920131e+00, -8.2219474e-02, -1.7797726e+00,\n         1.9186199e-02,  2.9872777e+00],\n       [-5.4818859e+00,  2.3786294e+00,  3.5859261e+00,  1.0720947e+00,\n         4.6697274e-01, -2.7484484e+00, -1.0758044e+00, -2.1809204e+00,\n         3.5498074e-01,  3.1307592e+00],\n       [-6.4106817e+00,  2.0626850e+00,  2.0597873e+00,  1.5571512e+00,\n         6.1938918e-01, -2.4180110e+00,  5.3068364e-01, -1.1132077e+00,\n        -8.9691371e-02,  1.4451797e+00],\n       [-4.5398288e+00,  1.4331827e+00,  2.6453276e+00,  4.8160100e-01,\n         7.2472489e-01, -4.0331841e+00, -3.7598571e-01, -2.5836568e+00,\n         3.4458816e-02,  1.7487735e+00],\n       [-5.9373417e+00,  7.9067844e-01,  3.2109900e+00,  6.6137612e-01,\n        -2.2523654e-01, -4.1539898e+00,  4.8169219e-01, -2.2375419e+00,\n        -9.8938406e-02,  2.8825476e+00]], dtype=float32)>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6pwvwqWl9qiP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666274954818,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "6pwvwqWl9qiP",
    "outputId": "586b9725-4108-446c-e550-44545eae8a6d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<keras.engine.input_layer.InputLayer at 0x205881f68e0>,\n <__main__.alphanet_feature_Block at 0x205881f6340>,\n <keras.layers.core.Dropout at 0x205882e6df0>,\n <keras.layers.core.Dense at 0x20592c31c70>,\n <keras.layers.core.Dense at 0x20592c86880>,\n <keras.layers.core.Dense at 0x205f5747460>,\n <keras.layers.core.Dense at 0x20590da7ee0>,\n <keras.layers.core.Dense at 0x20592c2a3d0>,\n <keras.layers.core.Dense at 0x20592c2aa60>]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testb.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "s376ihCV9qiP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666274954818,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "s376ihCV9qiP",
    "outputId": "d53bf44f-04be-4f31-e233-e8f3798a5b17",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# 7+7*3+3=31\n",
    "print(len(testb_feature.layers))\n",
    "# input + feature + dropout + dense * 2\n",
    "print(len(testb.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "PujjexyA9qiP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666274954818,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "PujjexyA9qiP",
    "outputId": "64163e95-1e8b-48fd-eb4e-29efc3b61ae3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AlphaNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 9, 30)]           0         \n",
      "_________________________________________________________________\n",
      "alphanet_feature__block (alp (None, 702)               112       \n",
      "_________________________________________________________________\n",
      "Dropout1 (Dropout)           (None, 702)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 512)               359936    \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "Dense3 (Dense)               (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "Dense4 (Dense)               (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "Dense5 (Dense)               (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 534,938\n",
      "Trainable params: 534,882\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "testb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40Kdtn069qiP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666274954818,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "40Kdtn069qiP",
    "outputId": "41744c04-2656-4700-ca0c-bb7d075704e4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Variable 'alphanet_feature__block/batch_normalization/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_1/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_1/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_1/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_1/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_2/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_2/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_2/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_2/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_3/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_3/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_3/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_3/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_4/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_4/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_4/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_4/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_5/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_5/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_5/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_5/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_6/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_6/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_6/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_6/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_7/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_7/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_7/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_7/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_8/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_8/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_8/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_8/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_9/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_9/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_9/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_9/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_10/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_10/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_10/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_10/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_11/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_11/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_11/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_11/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_12/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_12/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_12/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_12/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_13/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_13/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_13/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_13/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_14/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_14/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_14/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_14/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_15/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_15/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_15/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_15/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_16/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_16/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_16/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_16/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_17/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_17/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_17/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_17/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_18/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_18/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_18/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_18/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_19/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_19/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_19/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_19/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_20/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_20/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_20/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_20/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_21/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_21/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_21/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_21/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_22/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_22/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_22/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_22/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_23/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_23/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_23/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_23/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_24/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_24/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_24/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_24/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_25/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_25/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_25/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_25/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_26/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_26/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_26/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_26/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_27/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_27/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_27/moving_mean:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n <tf.Variable 'alphanet_feature__block/batch_normalization_27/moving_variance:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Variable 'Dense1/kernel:0' shape=(702, 512) dtype=float32, numpy=\n array([[ 0.8972806 , -0.35422915,  0.1453067 , ..., -1.8164353 ,\n         -0.29399264, -0.41493443],\n        [-0.6469793 ,  0.8271215 ,  0.88199633, ...,  0.04794914,\n          1.3443379 , -0.52445215],\n        [-0.35131055,  1.7104204 ,  1.3802112 , ...,  1.2283701 ,\n         -0.89835316, -1.0382137 ],\n        ...,\n        [ 1.0782776 ,  0.06850757,  1.3076557 , ..., -1.8121094 ,\n         -0.6041949 ,  0.20686676],\n        [-0.36471653,  0.35782003,  0.71253014, ...,  0.24679157,\n          0.1846787 , -0.20387323],\n        [-0.8357668 ,  0.03771286, -1.8830535 , ...,  1.2071915 ,\n          0.04655789, -0.6570223 ]], dtype=float32)>,\n <tf.Variable 'Dense1/bias:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>,\n <tf.Variable 'Dense2/kernel:0' shape=(512, 256) dtype=float32, numpy=\n array([[-0.18104792, -0.9344847 , -0.52511775, ...,  1.4004295 ,\n          0.57110286,  1.2512465 ],\n        [-0.50358695,  0.59219676, -1.2841738 , ..., -1.5952208 ,\n          0.37737972,  1.4021195 ],\n        [ 0.9230778 ,  1.0828078 , -0.06574066, ...,  0.1798981 ,\n          0.46346426,  1.670441  ],\n        ...,\n        [-0.14149064,  1.3004973 , -0.18880415, ...,  0.154295  ,\n         -0.4916242 , -0.966885  ],\n        [ 0.50303024,  0.5062955 , -0.14839426, ...,  0.20648138,\n         -1.7779686 , -0.21683756],\n        [ 1.5970445 ,  0.6654239 , -0.70030504, ..., -1.9724032 ,\n          0.89312595,  0.8345413 ]], dtype=float32)>,\n <tf.Variable 'Dense2/bias:0' shape=(256,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0.], dtype=float32)>,\n <tf.Variable 'Dense3/kernel:0' shape=(256, 128) dtype=float32, numpy=\n array([[-0.79009956,  0.02946788, -0.38388819, ...,  1.4665635 ,\n         -0.37304997, -0.48743948],\n        [-1.3293076 ,  0.6919891 , -0.43965742, ...,  0.2697313 ,\n         -0.19415842, -0.11827244],\n        [ 0.02308542, -0.33430243, -0.94400346, ...,  0.5261364 ,\n         -0.78952974, -0.80832916],\n        ...,\n        [ 0.4013298 , -0.3827412 , -0.149656  , ..., -0.37900433,\n         -0.10206086, -0.57398033],\n        [-0.1453272 , -1.1880592 , -1.0367228 , ..., -0.97861624,\n          0.8021054 ,  0.4185089 ],\n        [ 0.51414776, -1.0021659 ,  0.54062057, ..., -1.1677088 ,\n         -0.37481856, -0.7071335 ]], dtype=float32)>,\n <tf.Variable 'Dense3/bias:0' shape=(128,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'Dense4/kernel:0' shape=(128, 64) dtype=float32, numpy=\n array([[-0.5042418 ,  0.17135143,  1.7410837 , ..., -1.6757534 ,\n         -0.9833544 , -0.3255503 ],\n        [-1.1592692 , -0.28944817,  0.09386928, ...,  1.342123  ,\n          0.35463423,  0.604522  ],\n        [-1.0683827 ,  0.78622717,  0.8871871 , ..., -0.9989304 ,\n          0.59733087,  1.0167352 ],\n        ...,\n        [-1.2621669 , -1.102312  , -1.3112394 , ...,  0.2692528 ,\n          0.1781381 ,  0.0139626 ],\n        [-0.6754043 , -0.33560994,  0.7535579 , ..., -0.95547545,\n          0.43551227, -0.6411713 ],\n        [-0.0057632 ,  1.9091718 , -1.2255176 , ..., -1.9423501 ,\n          0.13371018, -0.4942118 ]], dtype=float32)>,\n <tf.Variable 'Dense4/bias:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'Dense5/kernel:0' shape=(64, 32) dtype=float32, numpy=\n array([[ 1.0222985 ,  0.17313634, -1.0701267 , ..., -0.8943488 ,\n          0.56195974,  0.8855299 ],\n        [ 0.36855355,  0.4647248 , -0.65247476, ..., -0.9811055 ,\n          1.0279686 , -0.06160453],\n        [ 0.30390683, -0.4606056 ,  1.5458486 , ..., -1.5800745 ,\n         -0.4108316 , -1.3096776 ],\n        ...,\n        [-0.04797752, -0.92014956, -1.0967333 , ..., -0.36160102,\n         -1.6136312 , -0.33376506],\n        [-0.11584015,  0.1024839 , -1.4786662 , ..., -0.04669459,\n         -0.66969335, -0.49974152],\n        [ 0.06484012, -0.5947447 , -0.1521981 , ...,  1.2564352 ,\n         -0.42136213,  0.7781937 ]], dtype=float32)>,\n <tf.Variable 'Dense5/bias:0' shape=(32,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'Output/kernel:0' shape=(32, 10) dtype=float32, numpy=\n array([[ 0.4833778 , -0.9614075 ,  1.5656604 , -0.1421909 ,  0.55569464,\n         -1.6571989 ,  0.5514471 , -1.7218671 , -1.3154403 ,  1.0695655 ],\n        [ 0.54017866,  0.70330167, -0.83865434,  1.1602536 , -0.35750967,\n          0.7377016 , -1.6902395 , -0.64835215, -0.02777482,  1.2596586 ],\n        [ 0.4199528 , -0.04022091, -0.7935334 , -0.42721   , -1.1794219 ,\n          0.0984178 ,  1.7109745 ,  1.3936126 , -0.0122456 ,  0.11446817],\n        [-0.328554  , -1.9883677 ,  0.01153625, -1.9878701 , -0.6354898 ,\n          0.2527451 ,  0.13331361,  0.31510204, -1.732612  ,  0.9662094 ],\n        [-1.0680332 , -0.8704913 , -0.96181464,  0.86847746,  0.4321813 ,\n         -0.08254792,  0.3887165 ,  0.11120967,  0.54740924, -1.444572  ],\n        [-0.12930295, -0.20180228, -0.65960246,  0.5619402 ,  0.12151056,\n          0.04556329, -1.368514  ,  0.2406654 ,  0.3397469 ,  0.8968663 ],\n        [-0.8714473 , -0.11096006, -1.3438795 , -0.10352676, -0.20528784,\n         -1.3555654 ,  1.7493551 ,  0.19076937, -0.1458025 ,  0.7657959 ],\n        [-1.0033696 ,  1.0800828 , -0.32029423, -0.35430485, -0.07706226,\n         -0.14025453,  1.1626263 ,  0.80701023, -0.35273322,  1.7494771 ],\n        [-0.34236225,  0.26476252, -0.04311964,  0.8019329 , -0.7812773 ,\n          0.6723598 ,  0.10475208, -0.40273032, -1.6509162 , -1.3143914 ],\n        [-0.13328503,  0.49145645,  1.8416239 , -0.774744  ,  1.313383  ,\n         -0.90595716,  0.7429152 , -0.04456349, -0.46168953,  1.7319402 ],\n        [-1.6864913 , -0.5075167 ,  1.1521282 , -0.60026747, -0.91886413,\n         -0.5115745 , -0.10960019,  1.2692548 , -0.02316512,  0.2982373 ],\n        [-0.15339786, -1.3662051 , -0.14245886,  1.1673148 ,  1.4704862 ,\n         -0.01795614, -0.29863667, -0.6633085 ,  0.87900895, -0.37506452],\n        [-0.44803816,  0.7902242 ,  1.3022122 ,  0.05910335,  0.9098603 ,\n          0.98878455,  0.47506163, -0.5021412 ,  0.9554066 , -0.8225941 ],\n        [ 0.8897953 ,  0.00668686,  0.85768545, -0.35126594,  0.92893434,\n          1.1450428 , -0.25906295, -1.3551332 ,  0.04429356, -0.2939384 ],\n        [ 0.7276765 ,  0.71154255, -0.14528044, -0.17258206, -0.09780407,\n          0.50715923, -1.7906495 ,  0.6414339 , -0.77381563, -1.5301383 ],\n        [-0.03854311,  0.43384036,  0.42520463, -1.1342497 ,  0.26583377,\n         -0.80451345, -1.0149533 , -1.4263443 ,  1.1668792 , -1.5772246 ],\n        [-0.63930386,  0.1106098 ,  1.0477513 ,  0.4884338 ,  1.9161136 ,\n          0.9261854 ,  1.1623741 , -0.07992277, -0.1566068 , -0.21390282],\n        [-0.3024852 ,  0.72131884,  0.9227181 , -0.08690656,  0.4916237 ,\n         -0.51469386, -0.43059766,  0.2642784 , -0.8025957 , -0.48316148],\n        [-1.3522416 , -0.5308176 ,  1.4129622 , -0.6767501 , -0.9423618 ,\n         -0.7397538 ,  1.0567592 ,  0.14416125,  0.76209825, -0.21715245],\n        [-1.9780756 ,  0.06771192,  0.9481095 , -0.03673226,  0.978921  ,\n          1.361504  , -1.3374045 , -0.76690304,  1.026299  ,  0.11897887],\n        [-0.6537501 , -0.04402734,  0.41360143, -0.11595528,  0.12200716,\n         -0.5754038 ,  1.0029047 , -0.5005009 ,  1.1474138 ,  1.2136317 ],\n        [-0.24456327,  0.20940627, -0.6192283 , -0.6621559 , -0.66102505,\n          1.1838124 ,  0.65883315,  0.64872766, -1.2951522 ,  1.633746  ],\n        [ 0.21670182,  0.64186555, -1.6964992 ,  1.1527045 , -1.1502231 ,\n          0.62735534, -0.57539797, -0.3036937 , -0.80412894,  1.4265952 ],\n        [ 0.9125098 ,  0.04996258,  0.60457027,  0.7307697 , -0.8258701 ,\n         -1.4213907 ,  0.01316785, -1.1127008 , -1.8464136 , -1.8777875 ],\n        [ 0.01106298,  0.7904672 ,  0.9853913 , -1.5200332 ,  1.1858593 ,\n          0.26412985, -1.3286093 ,  0.74614847,  1.5455    , -1.5142891 ],\n        [ 0.7143896 , -0.5284164 , -0.96163356,  0.00696035, -1.4974154 ,\n          0.22850384, -0.2559946 , -0.6847723 ,  1.1650777 , -0.1089128 ],\n        [ 0.79773706, -0.15574498, -1.4132701 ,  0.12493202,  0.607809  ,\n         -0.247415  , -0.12684752,  1.0278459 , -0.30124477,  0.41123506],\n        [-0.4610584 ,  1.2694091 ,  1.1303277 ,  0.8134697 , -0.2579009 ,\n          0.0718949 ,  0.6374544 , -0.7032264 , -0.17266351, -0.3073649 ],\n        [ 0.02747092, -1.0878856 , -0.65899074,  1.7455417 , -0.29655418,\n          0.25365305, -0.63087654,  0.08668255,  1.3692253 ,  0.87743574],\n        [-0.07149533, -0.36225945, -0.34618998,  1.3367617 ,  0.62094015,\n         -1.7247622 ,  0.15432444,  0.38882616,  0.15515082,  1.7015837 ],\n        [ 0.5459839 ,  1.5987158 , -1.0023233 ,  0.15941788, -0.5627638 ,\n         -0.7898201 ,  1.3577628 ,  1.2065337 ,  1.7569648 , -0.29469562],\n        [-1.1875973 ,  0.90523994,  1.4961298 ,  0.2755197 ,  0.08331966,\n         -0.1307834 ,  1.1794033 ,  0.08229817, -0.29219285, -1.8317618 ]],\n       dtype=float32)>,\n <tf.Variable 'Output/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testb.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BFb1peMG9qiP",
   "metadata": {
    "id": "BFb1peMG9qiP",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5. Real Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "Jnoq1AOlEwsk",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1666274954818,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "Jnoq1AOlEwsk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "TRAIN_DIR = \"train_60\"\n",
    "VALID_DIR = \"valid_60\"\n",
    "SAVE_DIR = \"saved_model\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "\n",
    "def load_hdf5(file):\n",
    "    r\"\"\" \n",
    "    Load HDF5 data file and preprocess.\n",
    "    \"\"\"\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        X, y = f[\"X\"][...], f[\"y\"][...]\n",
    "    # preprocess: log(1+x)\n",
    "    X[5, :] = np.log(X[5, :] + 1)\n",
    "    X[6, :] = np.log(X[6, :] + 1)\n",
    "    y = np.log(y + 1)\n",
    "    return X, y\n",
    "\n",
    "def load_dataset(train_dir, valid_dir):\n",
    "    r\"\"\"\n",
    "    Load preprocessed datasets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_dir: str\n",
    "        Fold contains training datasets.\n",
    "    valid_dir: str\n",
    "        Fold contains test datasets.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    value: generator\n",
    "        A generator for tuples like (name, train_data, valid_data)\n",
    "    \"\"\"\n",
    "    \n",
    "    for file in os.listdir(train_dir):\n",
    "        name = file.split(\"_\")[0]\n",
    "        train_dt = tf.data.Dataset.from_tensor_slices(\n",
    "            load_hdf5(f\"{train_dir}/{name}_train.hdf5\")\n",
    "        )\n",
    "        valid_dt = tf.data.Dataset.from_tensor_slices(\n",
    "            load_hdf5(f\"{valid_dir}/{name}_valid.hdf5\")\n",
    "        )\n",
    "        yield (name, train_dt, valid_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "SKa09rxZJMSc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2087239,
     "status": "ok",
     "timestamp": 1666277042055,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "SKa09rxZJMSc",
    "outputId": "f38f6c16-4b03-4bfb-971d-1ef15ca056da",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "473/473 [==============================] - 46s 76ms/step - loss: 0.2928 - MSE: 0.2928 - val_loss: 0.0375 - val_MSE: 0.0375\n",
      "Epoch 2/100\n",
      "473/473 [==============================] - 36s 76ms/step - loss: 0.0314 - MSE: 0.0314 - val_loss: 0.0116 - val_MSE: 0.0116\n",
      "Epoch 3/100\n",
      "473/473 [==============================] - 34s 72ms/step - loss: 0.0125 - MSE: 0.0125 - val_loss: 0.0040 - val_MSE: 0.0040\n",
      "Epoch 4/100\n",
      "473/473 [==============================] - 44s 93ms/step - loss: 0.0059 - MSE: 0.0059 - val_loss: 0.0018 - val_MSE: 0.0018\n",
      "Epoch 5/100\n",
      "473/473 [==============================] - 19s 39ms/step - loss: 0.0031 - MSE: 0.0031 - val_loss: 9.5113e-04 - val_MSE: 9.5113e-04\n",
      "Epoch 6/100\n",
      "473/473 [==============================] - 20s 43ms/step - loss: 0.0018 - MSE: 0.0018 - val_loss: 5.7174e-04 - val_MSE: 5.7174e-04\n",
      "Epoch 7/100\n",
      "473/473 [==============================] - 20s 42ms/step - loss: 0.0012 - MSE: 0.0012 - val_loss: 3.6507e-04 - val_MSE: 3.6507e-04\n",
      "Epoch 8/100\n",
      "473/473 [==============================] - 28s 59ms/step - loss: 7.7024e-04 - MSE: 7.7024e-04 - val_loss: 2.5233e-04 - val_MSE: 2.5233e-04\n",
      "Epoch 9/100\n",
      "473/473 [==============================] - 23s 49ms/step - loss: 5.3540e-04 - MSE: 5.3540e-04 - val_loss: 1.8039e-04 - val_MSE: 1.8039e-04\n",
      "Epoch 10/100\n",
      "473/473 [==============================] - 22s 46ms/step - loss: 3.9430e-04 - MSE: 3.9430e-04 - val_loss: 1.3283e-04 - val_MSE: 1.3283e-04\n",
      "Epoch 11/100\n",
      "473/473 [==============================] - 19s 40ms/step - loss: 2.8690e-04 - MSE: 2.8690e-04 - val_loss: 9.7866e-05 - val_MSE: 9.7866e-05\n",
      "321/473 [===================>..........] - ETA: 5s - loss: 2.9500e-04 - MSE: 2.9500e-04Epoch 12/100\n",
      "473/473 [==============================] - 20s 42ms/step - loss: 2.1700e-04 - MSE: 2.1700e-04 - val_loss: 7.3875e-05 - val_MSE: 7.3875e-05\n",
      "Epoch 13/100\n",
      "473/473 [==============================] - 19s 41ms/step - loss: 1.6599e-04 - MSE: 1.6599e-04 - val_loss: 5.6705e-05 - val_MSE: 5.6705e-05\n",
      "Epoch 14/100\n",
      "473/473 [==============================] - 23s 48ms/step - loss: 1.2559e-04 - MSE: 1.2559e-04 - val_loss: 4.5070e-05 - val_MSE: 4.5070e-05\n",
      "Epoch 15/100\n",
      "473/473 [==============================] - 25s 54ms/step - loss: 9.8047e-05 - MSE: 9.8047e-05 - val_loss: 3.5311e-05 - val_MSE: 3.5311e-05\n",
      "Epoch 16/100\n",
      "473/473 [==============================] - 26s 54ms/step - loss: 7.7139e-05 - MSE: 7.7139e-05 - val_loss: 2.8317e-05 - val_MSE: 2.8317e-05\n",
      "Epoch 17/100\n",
      "473/473 [==============================] - 21s 45ms/step - loss: 6.1941e-05 - MSE: 6.1941e-05 - val_loss: 2.2894e-05 - val_MSE: 2.2894e-05\n",
      "Epoch 18/100\n",
      "473/473 [==============================] - 36s 76ms/step - loss: 4.7816e-05 - MSE: 4.7816e-05 - val_loss: 1.8565e-05 - val_MSE: 1.8565e-05\n",
      "Epoch 19/100\n",
      "473/473 [==============================] - 37s 78ms/step - loss: 3.8889e-05 - MSE: 3.8889e-05 - val_loss: 1.5603e-05 - val_MSE: 1.5603e-05\n",
      "Epoch 20/100\n",
      "473/473 [==============================] - 38s 80ms/step - loss: 3.1152e-05 - MSE: 3.1152e-05 - val_loss: 1.2883e-05 - val_MSE: 1.2883e-05\n",
      "Epoch 21/100\n",
      "473/473 [==============================] - 27s 57ms/step - loss: 2.4639e-05 - MSE: 2.4639e-05 - val_loss: 1.1002e-05 - val_MSE: 1.1002e-05\n",
      "Epoch 22/100\n",
      "473/473 [==============================] - 27s 57ms/step - loss: 2.0333e-05 - MSE: 2.0333e-05 - val_loss: 9.6571e-06 - val_MSE: 9.6571e-06\n",
      "Epoch 23/100\n",
      "473/473 [==============================] - 20s 42ms/step - loss: 1.7271e-05 - MSE: 1.7271e-05 - val_loss: 8.4402e-06 - val_MSE: 8.4402e-06\n",
      "Epoch 24/100\n",
      "473/473 [==============================] - 19s 39ms/step - loss: 1.4279e-05 - MSE: 1.4279e-05 - val_loss: 7.5283e-06 - val_MSE: 7.5283e-06\n",
      "Epoch 25/100\n",
      "473/473 [==============================] - 20s 42ms/step - loss: 1.2287e-05 - MSE: 1.2287e-05 - val_loss: 6.7809e-06 - val_MSE: 6.7809e-06\n",
      "Epoch 26/100\n",
      "473/473 [==============================] - 19s 40ms/step - loss: 1.0557e-05 - MSE: 1.0557e-05 - val_loss: 6.2454e-06 - val_MSE: 6.2454e-06\n",
      "Epoch 27/100\n",
      "473/473 [==============================] - 16s 33ms/step - loss: 9.5572e-06 - MSE: 9.5572e-06 - val_loss: 5.9202e-06 - val_MSE: 5.9202e-06\n",
      "Epoch 28/100\n",
      "473/473 [==============================] - 19s 41ms/step - loss: 8.5556e-06 - MSE: 8.5556e-06 - val_loss: 5.5182e-06 - val_MSE: 5.5182e-06\n",
      "Epoch 29/100\n",
      "473/473 [==============================] - 19s 40ms/step - loss: 7.9674e-06 - MSE: 7.9674e-06 - val_loss: 5.2907e-06 - val_MSE: 5.2907e-06\n",
      "Epoch 30/100\n",
      "473/473 [==============================] - 19s 41ms/step - loss: 7.3862e-06 - MSE: 7.3862e-06 - val_loss: 5.1011e-06 - val_MSE: 5.1011e-06\n",
      "Epoch 31/100\n",
      "473/473 [==============================] - 15s 33ms/step - loss: 6.9978e-06 - MSE: 6.9978e-06 - val_loss: 4.9730e-06 - val_MSE: 4.9730e-06\n",
      "Epoch 32/100\n",
      "473/473 [==============================] - 15s 33ms/step - loss: 6.6802e-06 - MSE: 6.6802e-06 - val_loss: 4.9231e-06 - val_MSE: 4.9231e-06\n",
      "Epoch 33/100\n",
      "473/473 [==============================] - 15s 32ms/step - loss: 6.4124e-06 - MSE: 6.4124e-06 - val_loss: 4.8659e-06 - val_MSE: 4.8659e-06\n",
      "Epoch 34/100\n",
      "473/473 [==============================] - 23s 42ms/step - loss: 6.2558e-06 - MSE: 6.2558e-06 - val_loss: 4.7582e-06 - val_MSE: 4.7582e-06\n",
      "Epoch 35/100\n",
      "473/473 [==============================] - 15s 32ms/step - loss: 6.1648e-06 - MSE: 6.1648e-06 - val_loss: 4.7134e-06 - val_MSE: 4.7134e-06\n",
      "Epoch 36/100\n",
      "473/473 [==============================] - 18s 39ms/step - loss: 6.0271e-06 - MSE: 6.0271e-06 - val_loss: 4.6942e-06 - val_MSE: 4.6942e-06\n",
      "Epoch 37/100\n",
      "473/473 [==============================] - 18s 38ms/step - loss: 5.8815e-06 - MSE: 5.8815e-06 - val_loss: 4.6615e-06 - val_MSE: 4.6615e-06\n",
      "Epoch 38/100\n",
      "473/473 [==============================] - 18s 39ms/step - loss: 5.8553e-06 - MSE: 5.8553e-06 - val_loss: 4.6479e-06 - val_MSE: 4.6479e-06\n",
      "Epoch 39/100\n",
      "473/473 [==============================] - 18s 39ms/step - loss: 5.7841e-06 - MSE: 5.7841e-06 - val_loss: 4.6483e-06 - val_MSE: 4.6483e-06\n",
      "Epoch 40/100\n",
      "473/473 [==============================] - 21s 45ms/step - loss: 5.7519e-06 - MSE: 5.7519e-06 - val_loss: 4.6341e-06 - val_MSE: 4.6341e-06\n",
      "Epoch 41/100\n",
      "473/473 [==============================] - 19s 39ms/step - loss: 5.7154e-06 - MSE: 5.7154e-06 - val_loss: 4.6181e-06 - val_MSE: 4.6181e-06\n",
      "Epoch 42/100\n",
      "473/473 [==============================] - 15s 32ms/step - loss: 5.6825e-06 - MSE: 5.6825e-06 - val_loss: 4.6141e-06 - val_MSE: 4.6141e-06\n",
      "Epoch 43/100\n",
      "473/473 [==============================] - 19s 39ms/step - loss: 5.6668e-06 - MSE: 5.6668e-06 - val_loss: 4.6105e-06 - val_MSE: 4.6105e-06\n",
      "Epoch 44/100\n",
      "473/473 [==============================] - 15s 32ms/step - loss: 5.6557e-06 - MSE: 5.6557e-06 - val_loss: 4.6085e-06 - val_MSE: 4.6085e-06\n",
      "Epoch 45/100\n",
      "473/473 [==============================] - 19s 40ms/step - loss: 5.6358e-06 - MSE: 5.6358e-06 - val_loss: 4.6070e-06 - val_MSE: 4.6070e-06\n",
      "Epoch 46/100\n",
      "473/473 [==============================] - 15s 31ms/step - loss: 5.6340e-06 - MSE: 5.6340e-06 - val_loss: 4.6053e-06 - val_MSE: 4.6053e-06\n",
      "Epoch 47/100\n",
      "473/473 [==============================] - 16s 34ms/step - loss: 5.6331e-06 - MSE: 5.6331e-06 - val_loss: 4.6044e-06 - val_MSE: 4.6044e-06\n",
      "Epoch 48/100\n",
      "473/473 [==============================] - 19s 39ms/step - loss: 5.6071e-06 - MSE: 5.6071e-06 - val_loss: 4.6035e-06 - val_MSE: 4.6035e-06\n",
      "Epoch 49/100\n",
      "473/473 [==============================] - 21s 39ms/step - loss: 5.6042e-06 - MSE: 5.6042e-06 - val_loss: 4.6029e-06 - val_MSE: 4.6029e-06\n",
      "Epoch 50/100\n",
      "473/473 [==============================] - 33s 71ms/step - loss: 5.6094e-06 - MSE: 5.6094e-06 - val_loss: 4.6017e-06 - val_MSE: 4.6017e-06\n",
      "Epoch 51/100\n",
      "473/473 [==============================] - 25s 53ms/step - loss: 5.6036e-06 - MSE: 5.6036e-06 - val_loss: 4.6016e-06 - val_MSE: 4.6016e-06\n",
      "Epoch 52/100\n",
      "473/473 [==============================] - 17s 36ms/step - loss: 5.6016e-06 - MSE: 5.6016e-06 - val_loss: 4.6023e-06 - val_MSE: 4.6023e-06\n",
      "Epoch 53/100\n",
      "473/473 [==============================] - 28s 59ms/step - loss: 5.5942e-06 - MSE: 5.5942e-06 - val_loss: 4.6063e-06 - val_MSE: 4.6063e-06\n",
      "Epoch 54/100\n",
      "473/473 [==============================] - 32s 67ms/step - loss: 5.5991e-06 - MSE: 5.5991e-06 - val_loss: 4.6009e-06 - val_MSE: 4.6009e-06\n",
      "Epoch 55/100\n",
      "473/473 [==============================] - 28s 60ms/step - loss: 5.5917e-06 - MSE: 5.5917e-06 - val_loss: 4.6022e-06 - val_MSE: 4.6022e-06\n",
      "Epoch 56/100\n",
      "473/473 [==============================] - 32s 67ms/step - loss: 5.5912e-06 - MSE: 5.5912e-06 - val_loss: 4.6032e-06 - val_MSE: 4.6032e-06\n",
      "Epoch 57/100\n",
      "473/473 [==============================] - 28s 60ms/step - loss: 5.5838e-06 - MSE: 5.5838e-06 - val_loss: 4.6030e-06 - val_MSE: 4.6030e-06\n",
      "Epoch 58/100\n",
      "473/473 [==============================] - 28s 60ms/step - loss: 5.5838e-06 - MSE: 5.5838e-06 - val_loss: 4.6017e-06 - val_MSE: 4.6017e-06\n",
      "Epoch 59/100\n",
      "473/473 [==============================] - 31s 66ms/step - loss: 5.5872e-06 - MSE: 5.5872e-06 - val_loss: 4.6043e-06 - val_MSE: 4.6043e-06\n",
      "INFO:tensorflow:Assets written to: saved_model/AR_60_log_s203_sigmoid_4layers\\assets\n",
      "Dataset AR has been trained and saved.\n",
      "Epoch 1/100\n",
      "366/366 [==============================] - 15s 32ms/step - loss: 0.2196 - MSE: 0.2196 - val_loss: 0.0413 - val_MSE: 0.0413\n",
      "Epoch 2/100\n",
      "366/366 [==============================] - 12s 32ms/step - loss: 0.0373 - MSE: 0.0373 - val_loss: 0.0128 - val_MSE: 0.0128\n",
      "Epoch 3/100\n",
      "366/366 [==============================] - 15s 40ms/step - loss: 0.0128 - MSE: 0.0128 - val_loss: 0.0057 - val_MSE: 0.0057\n",
      "Epoch 4/100\n",
      "366/366 [==============================] - 14s 38ms/step - loss: 0.0061 - MSE: 0.0061 - val_loss: 0.0032 - val_MSE: 0.0032\n",
      "Epoch 5/100\n",
      "366/366 [==============================] - 12s 32ms/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0020 - val_MSE: 0.0020\n",
      "Epoch 6/100\n",
      "366/366 [==============================] - 14s 40ms/step - loss: 0.0024 - MSE: 0.0024 - val_loss: 0.0012 - val_MSE: 0.0012\n",
      "Epoch 7/100\n",
      "366/366 [==============================] - 12s 32ms/step - loss: 0.0016 - MSE: 0.0016 - val_loss: 7.5597e-04 - val_MSE: 7.5597e-04\n",
      "Epoch 8/100\n",
      "366/366 [==============================] - 15s 40ms/step - loss: 0.0010 - MSE: 0.0010 - val_loss: 5.0118e-04 - val_MSE: 5.0118e-04\n",
      "Epoch 9/100\n",
      "366/366 [==============================] - 12s 34ms/step - loss: 8.0020e-04 - MSE: 8.0020e-04 - val_loss: 3.4646e-04 - val_MSE: 3.4646e-04\n",
      "Epoch 10/100\n",
      "366/366 [==============================] - 15s 40ms/step - loss: 5.9147e-04 - MSE: 5.9147e-04 - val_loss: 2.5963e-04 - val_MSE: 2.5963e-04\n",
      "Epoch 11/100\n",
      "366/366 [==============================] - 12s 32ms/step - loss: 4.3524e-04 - MSE: 4.3524e-04 - val_loss: 1.9173e-04 - val_MSE: 1.9173e-04\n",
      "Epoch 12/100\n",
      "366/366 [==============================] - 12s 32ms/step - loss: 3.4852e-04 - MSE: 3.4852e-04 - val_loss: 1.4062e-04 - val_MSE: 1.4062e-04\n",
      "Epoch 13/100\n",
      "366/366 [==============================] - 12s 32ms/step - loss: 2.6735e-04 - MSE: 2.6735e-04 - val_loss: 1.0529e-04 - val_MSE: 1.0529e-04\n",
      "Epoch 14/100\n",
      "366/366 [==============================] - 15s 41ms/step - loss: 2.1739e-04 - MSE: 2.1739e-04 - val_loss: 8.7351e-05 - val_MSE: 8.7351e-05\n",
      "Epoch 15/100\n",
      "366/366 [==============================] - 11s 31ms/step - loss: 1.7596e-04 - MSE: 1.7596e-04 - val_loss: 7.2775e-05 - val_MSE: 7.2775e-05\n",
      "Epoch 16/100\n",
      "366/366 [==============================] - 11s 30ms/step - loss: 1.3713e-04 - MSE: 1.3713e-04 - val_loss: 5.1925e-05 - val_MSE: 5.1925e-05\n",
      "Epoch 17/100\n",
      "366/366 [==============================] - 10s 29ms/step - loss: 1.1527e-04 - MSE: 1.1527e-04 - val_loss: 3.8756e-05 - val_MSE: 3.8756e-05\n",
      "Epoch 18/100\n",
      "366/366 [==============================] - 11s 30ms/step - loss: 8.8931e-05 - MSE: 8.8931e-05 - val_loss: 3.7221e-05 - val_MSE: 3.7221e-05\n",
      "Epoch 19/100\n",
      "366/366 [==============================] - 11s 31ms/step - loss: 7.2252e-05 - MSE: 7.2252e-05 - val_loss: 2.7595e-05 - val_MSE: 2.7595e-05\n",
      "Epoch 20/100\n",
      "366/366 [==============================] - 15s 40ms/step - loss: 6.0609e-05 - MSE: 6.0609e-05 - val_loss: 2.0264e-05 - val_MSE: 2.0264e-05\n",
      "Epoch 21/100\n",
      "366/366 [==============================] - 12s 32ms/step - loss: 5.0135e-05 - MSE: 5.0135e-05 - val_loss: 1.5898e-05 - val_MSE: 1.5898e-05\n",
      "Epoch 22/100\n",
      "366/366 [==============================] - 15s 42ms/step - loss: 3.8663e-05 - MSE: 3.8663e-05 - val_loss: 1.2832e-05 - val_MSE: 1.2832e-05\n",
      "Epoch 23/100\n",
      "366/366 [==============================] - 26s 72ms/step - loss: 3.0543e-05 - MSE: 3.0543e-05 - val_loss: 1.0149e-05 - val_MSE: 1.0149e-05\n",
      "Epoch 24/100\n",
      "366/366 [==============================] - 27s 74ms/step - loss: 2.6619e-05 - MSE: 2.6619e-05 - val_loss: 9.3996e-06 - val_MSE: 9.3996e-06\n",
      "Epoch 25/100\n",
      "366/366 [==============================] - 24s 65ms/step - loss: 2.1639e-05 - MSE: 2.1639e-05 - val_loss: 7.3991e-06 - val_MSE: 7.3991e-06\n",
      "Epoch 26/100\n",
      "366/366 [==============================] - 29s 80ms/step - loss: 1.6863e-05 - MSE: 1.6863e-05 - val_loss: 5.5478e-06 - val_MSE: 5.5478e-06\n",
      "Epoch 27/100\n",
      "366/366 [==============================] - 30s 82ms/step - loss: 1.3992e-05 - MSE: 1.3992e-05 - val_loss: 4.7584e-06 - val_MSE: 4.7584e-06\n",
      "Epoch 28/100\n",
      "366/366 [==============================] - 32s 87ms/step - loss: 1.2024e-05 - MSE: 1.2024e-05 - val_loss: 3.8045e-06 - val_MSE: 3.8045e-06\n",
      "Epoch 29/100\n",
      "366/366 [==============================] - 32s 87ms/step - loss: 9.2407e-06 - MSE: 9.2407e-06 - val_loss: 3.2854e-06 - val_MSE: 3.2854e-06\n",
      "Epoch 30/100\n",
      "366/366 [==============================] - 32s 88ms/step - loss: 8.1071e-06 - MSE: 8.1071e-06 - val_loss: 2.7923e-06 - val_MSE: 2.7923e-06\n",
      "Epoch 31/100\n",
      "366/366 [==============================] - 32s 87ms/step - loss: 6.7179e-06 - MSE: 6.7179e-06 - val_loss: 2.5446e-06 - val_MSE: 2.5446e-06\n",
      "Epoch 32/100\n",
      "366/366 [==============================] - 32s 87ms/step - loss: 5.8084e-06 - MSE: 5.8084e-06 - val_loss: 2.2526e-06 - val_MSE: 2.2526e-06\n",
      "Epoch 33/100\n",
      "366/366 [==============================] - 27s 75ms/step - loss: 4.7552e-06 - MSE: 4.7552e-06 - val_loss: 1.9994e-06 - val_MSE: 1.9994e-06\n",
      "Epoch 34/100\n",
      "366/366 [==============================] - 31s 84ms/step - loss: 4.2628e-06 - MSE: 4.2628e-06 - val_loss: 1.8680e-06 - val_MSE: 1.8680e-06\n",
      "Epoch 35/100\n",
      "366/366 [==============================] - 29s 79ms/step - loss: 3.7709e-06 - MSE: 3.7709e-06 - val_loss: 1.6058e-06 - val_MSE: 1.6058e-06\n",
      "Epoch 36/100\n",
      "366/366 [==============================] - 32s 87ms/step - loss: 3.3491e-06 - MSE: 3.3491e-06 - val_loss: 1.4096e-06 - val_MSE: 1.4096e-06\n",
      "Epoch 37/100\n",
      "366/366 [==============================] - 27s 75ms/step - loss: 3.0362e-06 - MSE: 3.0362e-06 - val_loss: 1.2769e-06 - val_MSE: 1.2769e-06\n",
      "Epoch 38/100\n",
      "366/366 [==============================] - 19s 51ms/step - loss: 2.6248e-06 - MSE: 2.6248e-06 - val_loss: 1.2525e-06 - val_MSE: 1.2525e-06\n",
      "Epoch 39/100\n",
      "366/366 [==============================] - 26s 70ms/step - loss: 2.3627e-06 - MSE: 2.3627e-06 - val_loss: 1.1187e-06 - val_MSE: 1.1187e-06\n",
      "Epoch 40/100\n",
      "366/366 [==============================] - 32s 88ms/step - loss: 2.4160e-06 - MSE: 2.4160e-06 - val_loss: 1.0381e-06 - val_MSE: 1.0381e-06\n",
      "Epoch 41/100\n",
      "366/366 [==============================] - 32s 87ms/step - loss: 2.1398e-06 - MSE: 2.1398e-06 - val_loss: 1.0027e-06 - val_MSE: 1.0027e-06\n",
      "Epoch 42/100\n",
      "366/366 [==============================] - 32s 87ms/step - loss: 1.9108e-06 - MSE: 1.9108e-06 - val_loss: 9.8098e-07 - val_MSE: 9.8098e-07\n",
      "Epoch 43/100\n",
      "366/366 [==============================] - 32s 87ms/step - loss: 1.8467e-06 - MSE: 1.8467e-06 - val_loss: 9.8886e-07 - val_MSE: 9.8886e-07\n",
      "Epoch 44/100\n",
      "366/366 [==============================] - 32s 88ms/step - loss: 1.7707e-06 - MSE: 1.7707e-06 - val_loss: 9.2210e-07 - val_MSE: 9.2210e-07\n",
      "Epoch 45/100\n",
      "366/366 [==============================] - 27s 74ms/step - loss: 1.7246e-06 - MSE: 1.7246e-06 - val_loss: 9.0156e-07 - val_MSE: 9.0156e-07\n",
      "Epoch 46/100\n",
      "366/366 [==============================] - 19s 53ms/step - loss: 1.7962e-06 - MSE: 1.7962e-06 - val_loss: 8.8932e-07 - val_MSE: 8.8932e-07\n",
      "Epoch 47/100\n",
      "366/366 [==============================] - 16s 45ms/step - loss: 1.6191e-06 - MSE: 1.6191e-06 - val_loss: 9.0232e-07 - val_MSE: 9.0232e-07\n",
      "Epoch 48/100\n",
      "366/366 [==============================] - 19s 53ms/step - loss: 1.5568e-06 - MSE: 1.5568e-06 - val_loss: 8.8364e-07 - val_MSE: 8.8364e-07\n",
      "Epoch 49/100\n",
      "366/366 [==============================] - 20s 54ms/step - loss: 1.5737e-06 - MSE: 1.5737e-06 - val_loss: 8.7134e-07 - val_MSE: 8.7134e-07\n",
      "Epoch 50/100\n",
      "366/366 [==============================] - 16s 44ms/step - loss: 1.4885e-06 - MSE: 1.4885e-06 - val_loss: 8.7222e-07 - val_MSE: 8.7222e-07\n",
      "Epoch 51/100\n",
      "366/366 [==============================] - 24s 65ms/step - loss: 1.5042e-06 - MSE: 1.5042e-06 - val_loss: 8.7050e-07 - val_MSE: 8.7050e-07\n",
      "Epoch 52/100\n",
      "366/366 [==============================] - 32s 87ms/step - loss: 1.4253e-06 - MSE: 1.4253e-06 - val_loss: 8.4989e-07 - val_MSE: 8.4989e-07\n",
      "Epoch 53/100\n",
      "366/366 [==============================] - 24s 65ms/step - loss: 1.4633e-06 - MSE: 1.4633e-06 - val_loss: 1.0314e-06 - val_MSE: 1.0314e-06\n",
      "Epoch 54/100\n",
      "366/366 [==============================] - 20s 54ms/step - loss: 1.4832e-06 - MSE: 1.4832e-06 - val_loss: 9.1056e-07 - val_MSE: 9.1056e-07\n",
      "Epoch 55/100\n",
      "366/366 [==============================] - 16s 45ms/step - loss: 1.4767e-06 - MSE: 1.4767e-06 - val_loss: 9.4996e-07 - val_MSE: 9.4996e-07\n",
      "Epoch 56/100\n",
      "366/366 [==============================] - 20s 54ms/step - loss: 1.5015e-06 - MSE: 1.5015e-06 - val_loss: 8.4832e-07 - val_MSE: 8.4832e-07\n",
      "Epoch 57/100\n",
      "366/366 [==============================] - 20s 54ms/step - loss: 1.3969e-06 - MSE: 1.3969e-06 - val_loss: 8.5611e-07 - val_MSE: 8.5611e-07\n",
      "Epoch 58/100\n",
      "366/366 [==============================] - 20s 54ms/step - loss: 1.4150e-06 - MSE: 1.4150e-06 - val_loss: 9.2400e-07 - val_MSE: 9.2400e-07\n",
      "Epoch 59/100\n",
      "366/366 [==============================] - 16s 45ms/step - loss: 1.4033e-06 - MSE: 1.4033e-06 - val_loss: 8.4994e-07 - val_MSE: 8.4994e-07\n",
      "Epoch 60/100\n",
      "366/366 [==============================] - 20s 54ms/step - loss: 1.4047e-06 - MSE: 1.4047e-06 - val_loss: 8.4924e-07 - val_MSE: 8.4924e-07\n",
      "Epoch 61/100\n",
      "366/366 [==============================] - 20s 54ms/step - loss: 1.4287e-06 - MSE: 1.4287e-06 - val_loss: 9.3564e-07 - val_MSE: 9.3564e-07\n",
      "INFO:tensorflow:Assets written to: saved_model/BAH_60_log_s203_sigmoid_4layers\\assets\n",
      "Dataset BAH has been trained and saved.\n",
      "Epoch 1/100\n",
      "460/460 [==============================] - 19s 34ms/step - loss: nan - MSE: nan - val_loss: nan - val_MSE: nan\n",
      "Epoch 2/100\n",
      "460/460 [==============================] - 12s 26ms/step - loss: nan - MSE: nan - val_loss: nan - val_MSE: nan\n",
      "Epoch 3/100\n",
      "460/460 [==============================] - 15s 33ms/step - loss: nan - MSE: nan - val_loss: nan - val_MSE: nan\n",
      "Epoch 4/100\n",
      "460/460 [==============================] - 15s 33ms/step - loss: nan - MSE: nan - val_loss: nan - val_MSE: nan\n",
      "Epoch 5/100\n",
      "460/460 [==============================] - 12s 26ms/step - loss: nan - MSE: nan - val_loss: nan - val_MSE: nan\n",
      "INFO:tensorflow:Assets written to: saved_model/FTI_60_log_s203_sigmoid_4layers\\assets\n",
      "Dataset FTI has been trained and saved.\n",
      "Epoch 1/100\n",
      "229/229 [==============================] - 11s 34ms/step - loss: 1.4802 - MSE: 1.4802 - val_loss: 0.3070 - val_MSE: 0.3070\n",
      "Epoch 2/100\n",
      "229/229 [==============================] - 7s 32ms/step - loss: 0.3496 - MSE: 0.3496 - val_loss: 0.2160 - val_MSE: 0.2160\n",
      "Epoch 3/100\n",
      "229/229 [==============================] - 5s 20ms/step - loss: 0.2265 - MSE: 0.2265 - val_loss: 0.1400 - val_MSE: 0.1400\n",
      "Epoch 4/100\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 0.1392 - MSE: 0.1392 - val_loss: 0.0655 - val_MSE: 0.0655\n",
      "Epoch 5/100\n",
      "229/229 [==============================] - 7s 32ms/step - loss: 0.0739 - MSE: 0.0739 - val_loss: 0.0311 - val_MSE: 0.0311\n",
      "Epoch 6/100\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 0.0415 - MSE: 0.0415 - val_loss: 0.0178 - val_MSE: 0.0178\n",
      "Epoch 7/100\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 0.0261 - MSE: 0.0261 - val_loss: 0.0113 - val_MSE: 0.0113\n",
      "Epoch 8/100\n",
      "229/229 [==============================] - 7s 32ms/step - loss: 0.0183 - MSE: 0.0183 - val_loss: 0.0076 - val_MSE: 0.0076\n",
      "Epoch 9/100\n",
      "229/229 [==============================] - 5s 20ms/step - loss: 0.0133 - MSE: 0.0133 - val_loss: 0.0054 - val_MSE: 0.0054\n",
      "Epoch 10/100\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 0.0098 - MSE: 0.0098 - val_loss: 0.0039 - val_MSE: 0.0039\n",
      "Epoch 11/100\n",
      "229/229 [==============================] - 7s 32ms/step - loss: 0.0077 - MSE: 0.0077 - val_loss: 0.0031 - val_MSE: 0.0031\n",
      "Epoch 12/100\n",
      "229/229 [==============================] - 7s 32ms/step - loss: 0.0060 - MSE: 0.0060 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 13/100\n",
      "229/229 [==============================] - 7s 32ms/step - loss: 0.0050 - MSE: 0.0050 - val_loss: 0.0019 - val_MSE: 0.0019\n",
      "Epoch 14/100\n",
      "229/229 [==============================] - 7s 31ms/step - loss: 0.0042 - MSE: 0.0042 - val_loss: 0.0015 - val_MSE: 0.0015\n",
      "Epoch 15/100\n",
      "229/229 [==============================] - 5s 20ms/step - loss: 0.0034 - MSE: 0.0034 - val_loss: 0.0012 - val_MSE: 0.0012\n",
      "Epoch 16/100\n",
      "229/229 [==============================] - 7s 32ms/step - loss: 0.0028 - MSE: 0.0028 - val_loss: 9.8878e-04 - val_MSE: 9.8878e-04\n",
      "Epoch 17/100\n",
      "229/229 [==============================] - 7s 32ms/step - loss: 0.0024 - MSE: 0.0024 - val_loss: 8.2901e-04 - val_MSE: 8.2901e-04\n",
      "Epoch 18/100\n",
      "229/229 [==============================] - 7s 31ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 6.7496e-04 - val_MSE: 6.7496e-04\n",
      "Epoch 19/100\n",
      "229/229 [==============================] - 6s 28ms/step - loss: 0.0018 - MSE: 0.0018 - val_loss: 5.6125e-04 - val_MSE: 5.6125e-04\n",
      "Epoch 20/100\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 0.0014 - MSE: 0.0014 - val_loss: 4.7848e-04 - val_MSE: 4.7848e-04\n",
      "Epoch 21/100\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 0.0012 - MSE: 0.0012 - val_loss: 4.0492e-04 - val_MSE: 4.0492e-04\n",
      "Epoch 22/100\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 0.0011 - MSE: 0.0011 - val_loss: 3.3549e-04 - val_MSE: 3.3549e-04\n",
      "Epoch 23/100\n",
      "229/229 [==============================] - 5s 21ms/step - loss: 9.3750e-04 - MSE: 9.3750e-04 - val_loss: 2.8711e-04 - val_MSE: 2.8711e-04\n",
      "Epoch 24/100\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 8.0028e-04 - MSE: 8.0028e-04 - val_loss: 2.4355e-04 - val_MSE: 2.4355e-04\n",
      "Epoch 25/100\n",
      "229/229 [==============================] - 7s 32ms/step - loss: 6.8223e-04 - MSE: 6.8223e-04 - val_loss: 2.0600e-04 - val_MSE: 2.0600e-04\n",
      "Epoch 26/100\n",
      "229/229 [==============================] - 7s 32ms/step - loss: 5.9237e-04 - MSE: 5.9237e-04 - val_loss: 1.7582e-04 - val_MSE: 1.7582e-04\n",
      "Epoch 27/100\n",
      "229/229 [==============================] - 10s 43ms/step - loss: 5.1758e-04 - MSE: 5.1758e-04 - val_loss: 1.4987e-04 - val_MSE: 1.4987e-04\n",
      "Epoch 28/100\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 4.4818e-04 - MSE: 4.4818e-04 - val_loss: 1.2858e-04 - val_MSE: 1.2858e-04\n",
      "Epoch 29/100\n",
      "229/229 [==============================] - 11s 47ms/step - loss: 3.8463e-04 - MSE: 3.8463e-04 - val_loss: 1.1060e-04 - val_MSE: 1.1060e-04\n",
      "Epoch 30/100\n",
      "229/229 [==============================] - 11s 47ms/step - loss: 3.3591e-04 - MSE: 3.3591e-04 - val_loss: 9.4242e-05 - val_MSE: 9.4242e-05\n",
      "Epoch 31/100\n",
      "229/229 [==============================] - 11s 46ms/step - loss: 2.9290e-04 - MSE: 2.9290e-04 - val_loss: 8.1381e-05 - val_MSE: 8.1381e-05\n",
      "Epoch 32/100\n",
      "229/229 [==============================] - 7s 32ms/step - loss: 2.5962e-04 - MSE: 2.5962e-04 - val_loss: 7.0404e-05 - val_MSE: 7.0404e-05\n",
      "Epoch 33/100\n",
      "229/229 [==============================] - 5s 20ms/step - loss: 2.2493e-04 - MSE: 2.2493e-04 - val_loss: 6.0493e-05 - val_MSE: 6.0493e-05\n",
      "Epoch 34/100\n",
      "229/229 [==============================] - 7s 32ms/step - loss: 1.8767e-04 - MSE: 1.8767e-04 - val_loss: 5.2185e-05 - val_MSE: 5.2185e-05\n",
      "Epoch 35/100\n",
      "229/229 [==============================] - 10s 45ms/step - loss: 1.6295e-04 - MSE: 1.6295e-04 - val_loss: 4.7383e-05 - val_MSE: 4.7383e-05\n",
      "Epoch 36/100\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 1.5021e-04 - MSE: 1.5021e-04 - val_loss: 3.9884e-05 - val_MSE: 3.9884e-05\n",
      "Epoch 37/100\n",
      "229/229 [==============================] - 9s 39ms/step - loss: 1.3000e-04 - MSE: 1.3000e-04 - val_loss: 3.5620e-05 - val_MSE: 3.5620e-05\n",
      "Epoch 38/100\n",
      "229/229 [==============================] - 17s 76ms/step - loss: 1.1059e-04 - MSE: 1.1059e-04 - val_loss: 3.0300e-05 - val_MSE: 3.0300e-05\n",
      "Epoch 39/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 1.0247e-04 - MSE: 1.0247e-04 - val_loss: 2.7401e-05 - val_MSE: 2.7401e-05\n",
      "Epoch 40/100\n",
      "229/229 [==============================] - 12s 52ms/step - loss: 8.9335e-05 - MSE: 8.9335e-05 - val_loss: 2.2691e-05 - val_MSE: 2.2691e-05\n",
      "Epoch 41/100\n",
      "229/229 [==============================] - 12s 52ms/step - loss: 7.3277e-05 - MSE: 7.3277e-05 - val_loss: 2.0047e-05 - val_MSE: 2.0047e-05\n",
      "Epoch 42/100\n",
      "229/229 [==============================] - 12s 52ms/step - loss: 6.8932e-05 - MSE: 6.8932e-05 - val_loss: 1.7742e-05 - val_MSE: 1.7742e-05\n",
      "Epoch 43/100\n",
      "229/229 [==============================] - 12s 52ms/step - loss: 5.5859e-05 - MSE: 5.5859e-05 - val_loss: 1.6352e-05 - val_MSE: 1.6352e-05\n",
      "Epoch 44/100\n",
      "229/229 [==============================] - 12s 52ms/step - loss: 5.0177e-05 - MSE: 5.0177e-05 - val_loss: 1.3889e-05 - val_MSE: 1.3889e-05\n",
      "Epoch 45/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 4.5804e-05 - MSE: 4.5804e-05 - val_loss: 1.2267e-05 - val_MSE: 1.2267e-05\n",
      "Epoch 46/100\n",
      "229/229 [==============================] - 12s 52ms/step - loss: 3.8655e-05 - MSE: 3.8655e-05 - val_loss: 1.1009e-05 - val_MSE: 1.1009e-05\n",
      "Epoch 47/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 3.8102e-05 - MSE: 3.8102e-05 - val_loss: 1.0158e-05 - val_MSE: 1.0158e-05\n",
      "Epoch 48/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 3.1939e-05 - MSE: 3.1939e-05 - val_loss: 9.2619e-06 - val_MSE: 9.2619e-06\n",
      "Epoch 49/100\n",
      "229/229 [==============================] - 21s 91ms/step - loss: 2.8350e-05 - MSE: 2.8350e-05 - val_loss: 8.2591e-06 - val_MSE: 8.2591e-06\n",
      "Epoch 50/100\n",
      "229/229 [==============================] - 23s 102ms/step - loss: 2.4483e-05 - MSE: 2.4483e-05 - val_loss: 7.2262e-06 - val_MSE: 7.2262e-06\n",
      "Epoch 51/100\n",
      "229/229 [==============================] - 24s 105ms/step - loss: 2.1778e-05 - MSE: 2.1778e-05 - val_loss: 6.7473e-06 - val_MSE: 6.7473e-06\n",
      "Epoch 52/100\n",
      "229/229 [==============================] - 21s 91ms/step - loss: 1.9064e-05 - MSE: 1.9064e-05 - val_loss: 6.6469e-06 - val_MSE: 6.6469e-06\n",
      "Epoch 53/100\n",
      "229/229 [==============================] - 24s 104ms/step - loss: 1.7380e-05 - MSE: 1.7380e-05 - val_loss: 5.5079e-06 - val_MSE: 5.5079e-06\n",
      "Epoch 54/100\n",
      "229/229 [==============================] - 23s 101ms/step - loss: 1.5826e-05 - MSE: 1.5826e-05 - val_loss: 5.3091e-06 - val_MSE: 5.3091e-06\n",
      "Epoch 55/100\n",
      "229/229 [==============================] - 20s 88ms/step - loss: 1.4061e-05 - MSE: 1.4061e-05 - val_loss: 4.9158e-06 - val_MSE: 4.9158e-06\n",
      "Epoch 56/100\n",
      "229/229 [==============================] - 24s 104ms/step - loss: 1.2468e-05 - MSE: 1.2468e-05 - val_loss: 4.3252e-06 - val_MSE: 4.3252e-06\n",
      "Epoch 57/100\n",
      "229/229 [==============================] - 21s 91ms/step - loss: 1.1205e-05 - MSE: 1.1205e-05 - val_loss: 4.1456e-06 - val_MSE: 4.1456e-06\n",
      "Epoch 58/100\n",
      "229/229 [==============================] - 27s 118ms/step - loss: 1.0114e-05 - MSE: 1.0114e-05 - val_loss: 3.8158e-06 - val_MSE: 3.8158e-06\n",
      "Epoch 59/100\n",
      "229/229 [==============================] - 24s 105ms/step - loss: 9.8129e-06 - MSE: 9.8129e-06 - val_loss: 3.7064e-06 - val_MSE: 3.7064e-06\n",
      "Epoch 60/100\n",
      "229/229 [==============================] - 22s 98ms/step - loss: 8.1981e-06 - MSE: 8.1981e-06 - val_loss: 3.3655e-06 - val_MSE: 3.3655e-06\n",
      "Epoch 61/100\n",
      "229/229 [==============================] - 22s 97ms/step - loss: 8.3738e-06 - MSE: 8.3738e-06 - val_loss: 3.4567e-06 - val_MSE: 3.4567e-06\n",
      "Epoch 62/100\n",
      "229/229 [==============================] - 16s 70ms/step - loss: 7.0426e-06 - MSE: 7.0426e-06 - val_loss: 3.0174e-06 - val_MSE: 3.0174e-06\n",
      "Epoch 63/100\n",
      "229/229 [==============================] - 19s 84ms/step - loss: 6.5266e-06 - MSE: 6.5266e-06 - val_loss: 3.8661e-06 - val_MSE: 3.8661e-06\n",
      "Epoch 64/100\n",
      "229/229 [==============================] - 19s 84ms/step - loss: 5.6936e-06 - MSE: 5.6936e-06 - val_loss: 3.5435e-06 - val_MSE: 3.5435e-06\n",
      "Epoch 65/100\n",
      "229/229 [==============================] - 23s 99ms/step - loss: 5.6988e-06 - MSE: 5.6988e-06 - val_loss: 2.9988e-06 - val_MSE: 2.9988e-06\n",
      "Epoch 66/100\n",
      "229/229 [==============================] - 22s 97ms/step - loss: 5.1232e-06 - MSE: 5.1232e-06 - val_loss: 2.5484e-06 - val_MSE: 2.5484e-06\n",
      "Epoch 67/100\n",
      "229/229 [==============================] - 15s 66ms/step - loss: 4.7154e-06 - MSE: 4.7154e-06 - val_loss: 2.8284e-06 - val_MSE: 2.8284e-06\n",
      "Epoch 68/100\n",
      "229/229 [==============================] - 12s 51ms/step - loss: 4.5766e-06 - MSE: 4.5766e-06 - val_loss: 2.4496e-06 - val_MSE: 2.4496e-06\n",
      "Epoch 69/100\n",
      "229/229 [==============================] - 14s 63ms/step - loss: 4.2289e-06 - MSE: 4.2289e-06 - val_loss: 2.6879e-06 - val_MSE: 2.6879e-06\n",
      "Epoch 70/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 3.7495e-06 - MSE: 3.7495e-06 - val_loss: 2.5147e-06 - val_MSE: 2.5147e-06\n",
      "Epoch 71/100\n",
      "229/229 [==============================] - 12s 54ms/step - loss: 3.7293e-06 - MSE: 3.7293e-06 - val_loss: 2.3569e-06 - val_MSE: 2.3569e-06\n",
      "Epoch 72/100\n",
      "229/229 [==============================] - 15s 68ms/step - loss: 3.4586e-06 - MSE: 3.4586e-06 - val_loss: 2.2170e-06 - val_MSE: 2.2170e-06\n",
      "Epoch 73/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 3.5234e-06 - MSE: 3.5234e-06 - val_loss: 2.2537e-06 - val_MSE: 2.2537e-06\n",
      "Epoch 74/100\n",
      "229/229 [==============================] - 12s 54ms/step - loss: 3.1078e-06 - MSE: 3.1078e-06 - val_loss: 2.5467e-06 - val_MSE: 2.5467e-06\n",
      "Epoch 75/100\n",
      "229/229 [==============================] - 16s 68ms/step - loss: 3.1175e-06 - MSE: 3.1175e-06 - val_loss: 2.3534e-06 - val_MSE: 2.3534e-06\n",
      "Epoch 76/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 3.2022e-06 - MSE: 3.2022e-06 - val_loss: 2.2435e-06 - val_MSE: 2.2435e-06\n",
      "Epoch 77/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 2.9127e-06 - MSE: 2.9127e-06 - val_loss: 2.1890e-06 - val_MSE: 2.1890e-06\n",
      "Epoch 78/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 2.7494e-06 - MSE: 2.7494e-06 - val_loss: 2.0821e-06 - val_MSE: 2.0821e-06\n",
      "Epoch 79/100\n",
      "229/229 [==============================] - 12s 54ms/step - loss: 2.7201e-06 - MSE: 2.7201e-06 - val_loss: 2.0587e-06 - val_MSE: 2.0587e-06\n",
      "Epoch 80/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 2.6555e-06 - MSE: 2.6555e-06 - val_loss: 2.0331e-06 - val_MSE: 2.0331e-06\n",
      "Epoch 81/100\n",
      "229/229 [==============================] - 12s 54ms/step - loss: 2.6657e-06 - MSE: 2.6657e-06 - val_loss: 2.0184e-06 - val_MSE: 2.0184e-06\n",
      "Epoch 82/100\n",
      "229/229 [==============================] - 15s 68ms/step - loss: 2.4961e-06 - MSE: 2.4961e-06 - val_loss: 2.2931e-06 - val_MSE: 2.2931e-06\n",
      "Epoch 83/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 2.5151e-06 - MSE: 2.5151e-06 - val_loss: 2.0860e-06 - val_MSE: 2.0860e-06\n",
      "Epoch 84/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 2.6643e-06 - MSE: 2.6643e-06 - val_loss: 2.1501e-06 - val_MSE: 2.1501e-06\n",
      "Epoch 85/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 2.4673e-06 - MSE: 2.4673e-06 - val_loss: 2.2658e-06 - val_MSE: 2.2658e-06\n",
      "Epoch 86/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 2.3522e-06 - MSE: 2.3522e-06 - val_loss: 1.9857e-06 - val_MSE: 1.9857e-06\n",
      "Epoch 87/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 2.3520e-06 - MSE: 2.3520e-06 - val_loss: 2.1566e-06 - val_MSE: 2.1566e-06\n",
      "Epoch 88/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 2.2953e-06 - MSE: 2.2953e-06 - val_loss: 2.0148e-06 - val_MSE: 2.0148e-06\n",
      "Epoch 89/100\n",
      "229/229 [==============================] - 12s 52ms/step - loss: 2.2682e-06 - MSE: 2.2682e-06 - val_loss: 1.9687e-06 - val_MSE: 1.9687e-06\n",
      "Epoch 90/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 2.2763e-06 - MSE: 2.2763e-06 - val_loss: 2.0305e-06 - val_MSE: 2.0305e-06\n",
      "Epoch 91/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 2.2657e-06 - MSE: 2.2657e-06 - val_loss: 1.9927e-06 - val_MSE: 1.9927e-06\n",
      "Epoch 92/100\n",
      "229/229 [==============================] - 16s 69ms/step - loss: 2.2136e-06 - MSE: 2.2136e-06 - val_loss: 1.9625e-06 - val_MSE: 1.9625e-06\n",
      "Epoch 93/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 2.2189e-06 - MSE: 2.2189e-06 - val_loss: 1.9770e-06 - val_MSE: 1.9770e-06\n",
      "Epoch 94/100\n",
      "229/229 [==============================] - 12s 52ms/step - loss: 2.1871e-06 - MSE: 2.1871e-06 - val_loss: 1.9652e-06 - val_MSE: 1.9652e-06\n",
      "Epoch 95/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 2.1879e-06 - MSE: 2.1879e-06 - val_loss: 1.9507e-06 - val_MSE: 1.9507e-06\n",
      "Epoch 96/100\n",
      "229/229 [==============================] - 16s 68ms/step - loss: 2.1750e-06 - MSE: 2.1750e-06 - val_loss: 1.9882e-06 - val_MSE: 1.9882e-06\n",
      "Epoch 97/100\n",
      "229/229 [==============================] - 12s 53ms/step - loss: 2.1722e-06 - MSE: 2.1722e-06 - val_loss: 1.9932e-06 - val_MSE: 1.9932e-06\n",
      "Epoch 98/100\n",
      "229/229 [==============================] - 12s 54ms/step - loss: 2.1564e-06 - MSE: 2.1564e-06 - val_loss: 2.1159e-06 - val_MSE: 2.1159e-06\n",
      "Epoch 99/100\n",
      "229/229 [==============================] - 18s 77ms/step - loss: 2.1378e-06 - MSE: 2.1378e-06 - val_loss: 2.0108e-06 - val_MSE: 2.0108e-06\n",
      "Epoch 100/100\n",
      "229/229 [==============================] - 10s 45ms/step - loss: 2.1521e-06 - MSE: 2.1521e-06 - val_loss: 1.9812e-06 - val_MSE: 1.9812e-06\n",
      "INFO:tensorflow:Assets written to: saved_model/HII_60_log_s203_sigmoid_4layers\\assets\n",
      "Dataset HII has been trained and saved.\n",
      "Epoch 1/100\n",
      "413/413 [==============================] - 28s 59ms/step - loss: 0.3392 - MSE: 0.3392 - val_loss: 0.0501 - val_MSE: 0.0501\n",
      "Epoch 2/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 0.0534 - MSE: 0.0534 - val_loss: 0.0122 - val_MSE: 0.0122\n",
      "Epoch 3/100\n",
      "413/413 [==============================] - 28s 67ms/step - loss: 0.0189 - MSE: 0.0189 - val_loss: 0.0052 - val_MSE: 0.0052\n",
      "Epoch 4/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 0.0093 - MSE: 0.0093 - val_loss: 0.0028 - val_MSE: 0.0028\n",
      "Epoch 5/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 0.0053 - MSE: 0.0053 - val_loss: 0.0017 - val_MSE: 0.0017\n",
      "Epoch 6/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 0.0032 - MSE: 0.0032 - val_loss: 0.0011 - val_MSE: 0.0011\n",
      "Epoch 7/100\n",
      "413/413 [==============================] - 28s 67ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 6.9953e-04 - val_MSE: 6.9953e-04\n",
      "Epoch 8/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 0.0015 - MSE: 0.0015 - val_loss: 4.8267e-04 - val_MSE: 4.8267e-04\n",
      "Epoch 9/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 9.8754e-04 - MSE: 9.8754e-04 - val_loss: 3.3353e-04 - val_MSE: 3.3353e-04\n",
      "Epoch 10/100\n",
      "413/413 [==============================] - 14s 35ms/step - loss: 7.0532e-04 - MSE: 7.0532e-04 - val_loss: 2.3374e-04 - val_MSE: 2.3374e-04\n",
      "Epoch 11/100\n",
      "413/413 [==============================] - 16s 39ms/step - loss: 5.0486e-04 - MSE: 5.0486e-04 - val_loss: 1.7235e-04 - val_MSE: 1.7235e-04\n",
      "Epoch 12/100\n",
      "413/413 [==============================] - 28s 67ms/step - loss: 3.5881e-04 - MSE: 3.5881e-04 - val_loss: 1.1710e-04 - val_MSE: 1.1710e-04\n",
      "Epoch 13/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 2.7081e-04 - MSE: 2.7081e-04 - val_loss: 9.1654e-05 - val_MSE: 9.1654e-05\n",
      "Epoch 14/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 2.0065e-04 - MSE: 2.0065e-04 - val_loss: 6.4034e-05 - val_MSE: 6.4034e-05\n",
      "Epoch 15/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 1.5064e-04 - MSE: 1.5064e-04 - val_loss: 4.5391e-05 - val_MSE: 4.5391e-05\n",
      "Epoch 16/100\n",
      "413/413 [==============================] - 24s 59ms/step - loss: 1.1126e-04 - MSE: 1.1126e-04 - val_loss: 3.1285e-05 - val_MSE: 3.1285e-05\n",
      "Epoch 17/100\n",
      "413/413 [==============================] - 27s 67ms/step - loss: 8.8574e-05 - MSE: 8.8574e-05 - val_loss: 3.1221e-05 - val_MSE: 3.1221e-05\n",
      "Epoch 18/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 6.7101e-05 - MSE: 6.7101e-05 - val_loss: 1.8677e-05 - val_MSE: 1.8677e-05\n",
      "Epoch 19/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 5.0327e-05 - MSE: 5.0327e-05 - val_loss: 1.2622e-05 - val_MSE: 1.2622e-05\n",
      "Epoch 20/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 3.9434e-05 - MSE: 3.9434e-05 - val_loss: 1.2176e-05 - val_MSE: 1.2176e-05\n",
      "Epoch 21/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 3.0349e-05 - MSE: 3.0349e-05 - val_loss: 7.1988e-06 - val_MSE: 7.1988e-06\n",
      "Epoch 22/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 2.5500e-05 - MSE: 2.5500e-05 - val_loss: 6.3508e-06 - val_MSE: 6.3508e-06\n",
      "Epoch 23/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 1.9263e-05 - MSE: 1.9263e-05 - val_loss: 4.7921e-06 - val_MSE: 4.7921e-06\n",
      "Epoch 24/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 1.6235e-05 - MSE: 1.6235e-05 - val_loss: 3.5947e-06 - val_MSE: 3.5947e-06\n",
      "Epoch 25/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 1.3375e-05 - MSE: 1.3375e-05 - val_loss: 2.9316e-06 - val_MSE: 2.9316e-06\n",
      "Epoch 26/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 9.9341e-06 - MSE: 9.9341e-06 - val_loss: 2.4278e-06 - val_MSE: 2.4278e-06\n",
      "Epoch 27/100\n",
      "413/413 [==============================] - 28s 67ms/step - loss: 8.5576e-06 - MSE: 8.5576e-06 - val_loss: 2.5253e-06 - val_MSE: 2.5253e-06\n",
      "Epoch 28/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 6.8992e-06 - MSE: 6.8992e-06 - val_loss: 1.6615e-06 - val_MSE: 1.6615e-06\n",
      "Epoch 29/100\n",
      "413/413 [==============================] - 24s 59ms/step - loss: 5.9716e-06 - MSE: 5.9716e-06 - val_loss: 1.4306e-06 - val_MSE: 1.4306e-06\n",
      "Epoch 30/100\n",
      "413/413 [==============================] - 28s 67ms/step - loss: 4.7998e-06 - MSE: 4.7998e-06 - val_loss: 1.4524e-06 - val_MSE: 1.4524e-06\n",
      "Epoch 31/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 3.9901e-06 - MSE: 3.9901e-06 - val_loss: 1.1768e-06 - val_MSE: 1.1768e-06\n",
      "Epoch 32/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 3.7002e-06 - MSE: 3.7002e-06 - val_loss: 1.0396e-06 - val_MSE: 1.0396e-06\n",
      "Epoch 33/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 2.9873e-06 - MSE: 2.9873e-06 - val_loss: 1.0104e-06 - val_MSE: 1.0104e-06\n",
      "Epoch 34/100\n",
      "413/413 [==============================] - 28s 67ms/step - loss: 2.8042e-06 - MSE: 2.8042e-06 - val_loss: 9.2417e-07 - val_MSE: 9.2417e-07\n",
      "Epoch 35/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 2.4358e-06 - MSE: 2.4358e-06 - val_loss: 9.2181e-07 - val_MSE: 9.2181e-07\n",
      "Epoch 36/100\n",
      "413/413 [==============================] - 24s 59ms/step - loss: 2.2685e-06 - MSE: 2.2685e-06 - val_loss: 8.7068e-07 - val_MSE: 8.7068e-07\n",
      "Epoch 37/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 1.9666e-06 - MSE: 1.9666e-06 - val_loss: 8.0970e-07 - val_MSE: 8.0970e-07\n",
      "Epoch 38/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 1.9252e-06 - MSE: 1.9252e-06 - val_loss: 1.1732e-06 - val_MSE: 1.1732e-06\n",
      "Epoch 39/100\n",
      "413/413 [==============================] - 24s 59ms/step - loss: 1.7211e-06 - MSE: 1.7211e-06 - val_loss: 8.4541e-07 - val_MSE: 8.4541e-07\n",
      "Epoch 40/100\n",
      "413/413 [==============================] - 24s 59ms/step - loss: 1.7416e-06 - MSE: 1.7416e-06 - val_loss: 8.6633e-07 - val_MSE: 8.6633e-07\n",
      "Epoch 41/100\n",
      "413/413 [==============================] - 28s 67ms/step - loss: 1.5468e-06 - MSE: 1.5468e-06 - val_loss: 7.5013e-07 - val_MSE: 7.5013e-07\n",
      "Epoch 42/100\n",
      "413/413 [==============================] - 24s 59ms/step - loss: 1.5143e-06 - MSE: 1.5143e-06 - val_loss: 8.1345e-07 - val_MSE: 8.1345e-07\n",
      "Epoch 43/100\n",
      "413/413 [==============================] - 24s 59ms/step - loss: 1.4548e-06 - MSE: 1.4548e-06 - val_loss: 7.2290e-07 - val_MSE: 7.2290e-07\n",
      "Epoch 44/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 1.4144e-06 - MSE: 1.4144e-06 - val_loss: 8.6738e-07 - val_MSE: 8.6738e-07\n",
      "Epoch 45/100\n",
      "413/413 [==============================] - 16s 39ms/step - loss: 1.3674e-06 - MSE: 1.3674e-06 - val_loss: 7.1141e-07 - val_MSE: 7.1141e-07\n",
      "Epoch 46/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 1.3099e-06 - MSE: 1.3099e-06 - val_loss: 7.5844e-07 - val_MSE: 7.5844e-07\n",
      "Epoch 47/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 1.3114e-06 - MSE: 1.3114e-06 - val_loss: 7.2547e-07 - val_MSE: 7.2547e-07\n",
      "Epoch 48/100\n",
      "413/413 [==============================] - 28s 67ms/step - loss: 1.2898e-06 - MSE: 1.2898e-06 - val_loss: 6.9548e-07 - val_MSE: 6.9548e-07\n",
      "Epoch 49/100\n",
      "413/413 [==============================] - 24s 59ms/step - loss: 1.2764e-06 - MSE: 1.2764e-06 - val_loss: 6.9414e-07 - val_MSE: 6.9414e-07\n",
      "Epoch 50/100\n",
      "413/413 [==============================] - 16s 38ms/step - loss: 1.2443e-06 - MSE: 1.2443e-06 - val_loss: 7.0008e-07 - val_MSE: 7.0008e-07\n",
      "Epoch 51/100\n",
      "413/413 [==============================] - 14s 33ms/step - loss: 1.2408e-06 - MSE: 1.2408e-06 - val_loss: 6.9018e-07 - val_MSE: 6.9018e-07\n",
      "Epoch 52/100\n",
      "413/413 [==============================] - 12s 29ms/step - loss: 1.2186e-06 - MSE: 1.2186e-06 - val_loss: 6.8982e-07 - val_MSE: 6.8982e-07\n",
      "Epoch 53/100\n",
      "413/413 [==============================] - 12s 30ms/step - loss: 1.2239e-06 - MSE: 1.2239e-06 - val_loss: 6.9651e-07 - val_MSE: 6.9651e-07\n",
      "Epoch 54/100\n",
      "413/413 [==============================] - 12s 30ms/step - loss: 1.2203e-06 - MSE: 1.2203e-06 - val_loss: 7.0769e-07 - val_MSE: 7.0769e-07\n",
      "Epoch 55/100\n",
      "413/413 [==============================] - 15s 36ms/step - loss: 1.2026e-06 - MSE: 1.2026e-06 - val_loss: 7.0477e-07 - val_MSE: 7.0477e-07\n",
      "Epoch 56/100\n",
      "413/413 [==============================] - 12s 28ms/step - loss: 1.2259e-06 - MSE: 1.2259e-06 - val_loss: 8.3375e-07 - val_MSE: 8.3375e-07\n",
      "Epoch 57/100\n",
      "413/413 [==============================] - 15s 37ms/step - loss: 1.2291e-06 - MSE: 1.2291e-06 - val_loss: 8.5726e-07 - val_MSE: 8.5726e-07\n",
      "INFO:tensorflow:Assets written to: saved_model/LMT_60_log_s203_sigmoid_4layers\\assets\n",
      "Dataset LMT has been trained and saved.\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 11s 39ms/step - loss: 0.4758 - MSE: 0.4758 - val_loss: 0.1324 - val_MSE: 0.1324\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 0.1061 - MSE: 0.1061 - val_loss: 0.0313 - val_MSE: 0.0313\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.0405 - MSE: 0.0405 - val_loss: 0.0132 - val_MSE: 0.0132\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.0213 - MSE: 0.0213 - val_loss: 0.0075 - val_MSE: 0.0075\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.0133 - MSE: 0.0133 - val_loss: 0.0048 - val_MSE: 0.0048\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.0088 - MSE: 0.0088 - val_loss: 0.0034 - val_MSE: 0.0034\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.0067 - MSE: 0.0067 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.0048 - MSE: 0.0048 - val_loss: 0.0019 - val_MSE: 0.0019\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0015 - val_MSE: 0.0015\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.0029 - MSE: 0.0029 - val_loss: 0.0012 - val_MSE: 0.0012\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.0024 - MSE: 0.0024 - val_loss: 9.2449e-04 - val_MSE: 9.2449e-04\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.0019 - MSE: 0.0019 - val_loss: 7.5231e-04 - val_MSE: 7.5231e-04\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.0016 - MSE: 0.0016 - val_loss: 6.1680e-04 - val_MSE: 6.1680e-04\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.0013 - MSE: 0.0013 - val_loss: 5.1533e-04 - val_MSE: 5.1533e-04\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.0011 - MSE: 0.0011 - val_loss: 4.3276e-04 - val_MSE: 4.3276e-04\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 9.2077e-04 - MSE: 9.2077e-04 - val_loss: 3.5950e-04 - val_MSE: 3.5950e-04\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 7.6834e-04 - MSE: 7.6834e-04 - val_loss: 3.0317e-04 - val_MSE: 3.0317e-04\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 6.7208e-04 - MSE: 6.7208e-04 - val_loss: 2.5676e-04 - val_MSE: 2.5676e-04\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 10s 53ms/step - loss: 5.7036e-04 - MSE: 5.7036e-04 - val_loss: 2.2020e-04 - val_MSE: 2.2020e-04\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 5.0402e-04 - MSE: 5.0402e-04 - val_loss: 1.9107e-04 - val_MSE: 1.9107e-04\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 4.4025e-04 - MSE: 4.4025e-04 - val_loss: 1.6145e-04 - val_MSE: 1.6145e-04\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 3.6281e-04 - MSE: 3.6281e-04 - val_loss: 1.3943e-04 - val_MSE: 1.3943e-04\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 3.3368e-04 - MSE: 3.3368e-04 - val_loss: 1.2026e-04 - val_MSE: 1.2026e-04\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 2.9133e-04 - MSE: 2.9133e-04 - val_loss: 1.0442e-04 - val_MSE: 1.0442e-04\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 2.3689e-04 - MSE: 2.3689e-04 - val_loss: 9.0848e-05 - val_MSE: 9.0848e-05\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 2.1727e-04 - MSE: 2.1727e-04 - val_loss: 7.9903e-05 - val_MSE: 7.9903e-05\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.8598e-04 - MSE: 1.8598e-04 - val_loss: 6.9737e-05 - val_MSE: 6.9737e-05\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 1.6449e-04 - MSE: 1.6449e-04 - val_loss: 6.1059e-05 - val_MSE: 6.1059e-05\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 1.4593e-04 - MSE: 1.4593e-04 - val_loss: 5.3857e-05 - val_MSE: 5.3857e-05\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 1.2771e-04 - MSE: 1.2771e-04 - val_loss: 4.7661e-05 - val_MSE: 4.7661e-05\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 1.1029e-04 - MSE: 1.1029e-04 - val_loss: 4.1972e-05 - val_MSE: 4.1972e-05\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 1.0347e-04 - MSE: 1.0347e-04 - val_loss: 3.7146e-05 - val_MSE: 3.7146e-05\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 8.7405e-05 - MSE: 8.7405e-05 - val_loss: 3.2353e-05 - val_MSE: 3.2353e-05\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 7.8907e-05 - MSE: 7.8907e-05 - val_loss: 2.8235e-05 - val_MSE: 2.8235e-05\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 7.1266e-05 - MSE: 7.1266e-05 - val_loss: 2.4937e-05 - val_MSE: 2.4937e-05\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 5.9898e-05 - MSE: 5.9898e-05 - val_loss: 2.2661e-05 - val_MSE: 2.2661e-05\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 10s 52ms/step - loss: 5.4938e-05 - MSE: 5.4938e-05 - val_loss: 2.0054e-05 - val_MSE: 2.0054e-05\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 4.9791e-05 - MSE: 4.9791e-05 - val_loss: 1.7505e-05 - val_MSE: 1.7505e-05\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 10s 52ms/step - loss: 4.5305e-05 - MSE: 4.5305e-05 - val_loss: 1.5981e-05 - val_MSE: 1.5981e-05\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 4.3106e-05 - MSE: 4.3106e-05 - val_loss: 1.4089e-05 - val_MSE: 1.4089e-05\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 3.7118e-05 - MSE: 3.7118e-05 - val_loss: 1.2745e-05 - val_MSE: 1.2745e-05\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 3.3939e-05 - MSE: 3.3939e-05 - val_loss: 1.2052e-05 - val_MSE: 1.2052e-05\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 3.0751e-05 - MSE: 3.0751e-05 - val_loss: 1.0534e-05 - val_MSE: 1.0534e-05\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 10s 52ms/step - loss: 2.6445e-05 - MSE: 2.6445e-05 - val_loss: 9.6323e-06 - val_MSE: 9.6323e-06\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 2.5086e-05 - MSE: 2.5086e-05 - val_loss: 8.8610e-06 - val_MSE: 8.8610e-06\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 2.3462e-05 - MSE: 2.3462e-05 - val_loss: 8.0804e-06 - val_MSE: 8.0804e-06\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 2.0974e-05 - MSE: 2.0974e-05 - val_loss: 7.3740e-06 - val_MSE: 7.3740e-06\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 1.9785e-05 - MSE: 1.9785e-05 - val_loss: 6.8573e-06 - val_MSE: 6.8573e-06\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 1.7755e-05 - MSE: 1.7755e-05 - val_loss: 6.4481e-06 - val_MSE: 6.4481e-06\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 1.6515e-05 - MSE: 1.6515e-05 - val_loss: 5.9699e-06 - val_MSE: 5.9699e-06\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 1.5033e-05 - MSE: 1.5033e-05 - val_loss: 5.9941e-06 - val_MSE: 5.9941e-06\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 1.3230e-05 - MSE: 1.3230e-05 - val_loss: 5.2995e-06 - val_MSE: 5.2995e-06\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 7s 35ms/step - loss: 1.3299e-05 - MSE: 1.3299e-05 - val_loss: 5.3964e-06 - val_MSE: 5.3964e-06\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 1.1855e-05 - MSE: 1.1855e-05 - val_loss: 4.9176e-06 - val_MSE: 4.9176e-06\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 1.0605e-05 - MSE: 1.0605e-05 - val_loss: 4.5316e-06 - val_MSE: 4.5316e-06\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 9.7695e-06 - MSE: 9.7695e-06 - val_loss: 4.2996e-06 - val_MSE: 4.2996e-06\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 9.0474e-06 - MSE: 9.0474e-06 - val_loss: 4.1312e-06 - val_MSE: 4.1312e-06\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 8.6611e-06 - MSE: 8.6611e-06 - val_loss: 4.0882e-06 - val_MSE: 4.0882e-06\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 8.5859e-06 - MSE: 8.5859e-06 - val_loss: 3.9882e-06 - val_MSE: 3.9882e-06\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 7.9033e-06 - MSE: 7.9033e-06 - val_loss: 3.7106e-06 - val_MSE: 3.7106e-06\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 7.7233e-06 - MSE: 7.7233e-06 - val_loss: 3.5943e-06 - val_MSE: 3.5943e-06\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 7.0335e-06 - MSE: 7.0335e-06 - val_loss: 3.5944e-06 - val_MSE: 3.5944e-06\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 6.8449e-06 - MSE: 6.8449e-06 - val_loss: 3.5285e-06 - val_MSE: 3.5285e-06\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 6.4445e-06 - MSE: 6.4445e-06 - val_loss: 3.4697e-06 - val_MSE: 3.4697e-06\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 6.0931e-06 - MSE: 6.0931e-06 - val_loss: 3.3105e-06 - val_MSE: 3.3105e-06\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 5.7185e-06 - MSE: 5.7185e-06 - val_loss: 3.2114e-06 - val_MSE: 3.2114e-06\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 5.6077e-06 - MSE: 5.6077e-06 - val_loss: 3.1851e-06 - val_MSE: 3.1851e-06\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 5.2139e-06 - MSE: 5.2139e-06 - val_loss: 3.3778e-06 - val_MSE: 3.3778e-06\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 5.1813e-06 - MSE: 5.1813e-06 - val_loss: 3.1325e-06 - val_MSE: 3.1325e-06\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 4.9064e-06 - MSE: 4.9064e-06 - val_loss: 3.2756e-06 - val_MSE: 3.2756e-06\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 4.8397e-06 - MSE: 4.8397e-06 - val_loss: 3.0451e-06 - val_MSE: 3.0451e-06\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 4.7396e-06 - MSE: 4.7396e-06 - val_loss: 3.0467e-06 - val_MSE: 3.0467e-06\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 4.5731e-06 - MSE: 4.5731e-06 - val_loss: 3.0762e-06 - val_MSE: 3.0762e-06\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 4.7058e-06 - MSE: 4.7058e-06 - val_loss: 2.9362e-06 - val_MSE: 2.9362e-06\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 4.3562e-06 - MSE: 4.3562e-06 - val_loss: 2.9136e-06 - val_MSE: 2.9136e-06\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 4.3993e-06 - MSE: 4.3993e-06 - val_loss: 2.9056e-06 - val_MSE: 2.9056e-06\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 4.3067e-06 - MSE: 4.3067e-06 - val_loss: 2.8755e-06 - val_MSE: 2.8755e-06\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 4.2451e-06 - MSE: 4.2451e-06 - val_loss: 2.8939e-06 - val_MSE: 2.8939e-06\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 4.1650e-06 - MSE: 4.1650e-06 - val_loss: 2.8775e-06 - val_MSE: 2.8775e-06\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 4.1070e-06 - MSE: 4.1070e-06 - val_loss: 2.8308e-06 - val_MSE: 2.8308e-06\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 4.0124e-06 - MSE: 4.0124e-06 - val_loss: 2.8224e-06 - val_MSE: 2.8224e-06\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 4.0006e-06 - MSE: 4.0006e-06 - val_loss: 2.8667e-06 - val_MSE: 2.8667e-06\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.9068e-06 - MSE: 3.9068e-06 - val_loss: 2.8076e-06 - val_MSE: 2.8076e-06\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.9712e-06 - MSE: 3.9712e-06 - val_loss: 2.8104e-06 - val_MSE: 2.8104e-06\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.8936e-06 - MSE: 3.8936e-06 - val_loss: 2.7914e-06 - val_MSE: 2.7914e-06\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.8987e-06 - MSE: 3.8987e-06 - val_loss: 2.8289e-06 - val_MSE: 2.8289e-06\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.8498e-06 - MSE: 3.8498e-06 - val_loss: 2.7833e-06 - val_MSE: 2.7833e-06\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.8352e-06 - MSE: 3.8352e-06 - val_loss: 2.8601e-06 - val_MSE: 2.8601e-06\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.7837e-06 - MSE: 3.7837e-06 - val_loss: 2.7894e-06 - val_MSE: 2.7894e-06\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.8073e-06 - MSE: 3.8073e-06 - val_loss: 2.8327e-06 - val_MSE: 2.8327e-06\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.7946e-06 - MSE: 3.7946e-06 - val_loss: 2.8265e-06 - val_MSE: 2.8265e-06\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 3.7771e-06 - MSE: 3.7771e-06 - val_loss: 2.8561e-06 - val_MSE: 2.8561e-06\n",
      "INFO:tensorflow:Assets written to: saved_model/MLI_60_log_s203_sigmoid_4layers\\assets\n",
      "Dataset MLI has been trained and saved.\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 18s 34ms/step - loss: 2.5549 - MSE: 2.5549 - val_loss: 0.0661 - val_MSE: 0.0661\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 21s 48ms/step - loss: 0.0572 - MSE: 0.0572 - val_loss: 0.0179 - val_MSE: 0.0179\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 18s 40ms/step - loss: 0.0220 - MSE: 0.0220 - val_loss: 0.0104 - val_MSE: 0.0104\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 18s 40ms/step - loss: 0.0127 - MSE: 0.0127 - val_loss: 0.0068 - val_MSE: 0.0068\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 21s 47ms/step - loss: 0.0084 - MSE: 0.0084 - val_loss: 0.0046 - val_MSE: 0.0046\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 14s 32ms/step - loss: 0.0058 - MSE: 0.0058 - val_loss: 0.0032 - val_MSE: 0.0032\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 18s 41ms/step - loss: 0.0042 - MSE: 0.0042 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 21s 47ms/step - loss: 0.0032 - MSE: 0.0032 - val_loss: 0.0015 - val_MSE: 0.0015\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 18s 40ms/step - loss: 0.0024 - MSE: 0.0024 - val_loss: 0.0011 - val_MSE: 0.0011\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 14s 32ms/step - loss: 0.0018 - MSE: 0.0018 - val_loss: 7.8827e-04 - val_MSE: 7.8827e-04\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 14s 32ms/step - loss: 0.0013 - MSE: 0.0013 - val_loss: 5.5984e-04 - val_MSE: 5.5984e-04\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 15s 33ms/step - loss: 0.0010 - MSE: 0.0010 - val_loss: 3.9468e-04 - val_MSE: 3.9468e-04\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 18s 39ms/step - loss: 7.9383e-04 - MSE: 7.9383e-04 - val_loss: 2.9645e-04 - val_MSE: 2.9645e-04\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 14s 32ms/step - loss: 5.9455e-04 - MSE: 5.9455e-04 - val_loss: 2.2361e-04 - val_MSE: 2.2361e-04\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 14s 32ms/step - loss: 4.6465e-04 - MSE: 4.6465e-04 - val_loss: 1.6067e-04 - val_MSE: 1.6067e-04\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 15s 33ms/step - loss: 3.4918e-04 - MSE: 3.4918e-04 - val_loss: 1.2133e-04 - val_MSE: 1.2133e-04\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 22s 49ms/step - loss: 2.7864e-04 - MSE: 2.7864e-04 - val_loss: 9.3519e-05 - val_MSE: 9.3519e-05\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 21s 47ms/step - loss: 2.1846e-04 - MSE: 2.1846e-04 - val_loss: 7.3379e-05 - val_MSE: 7.3379e-05\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 18s 40ms/step - loss: 1.6752e-04 - MSE: 1.6752e-04 - val_loss: 5.6485e-05 - val_MSE: 5.6485e-05\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 21s 47ms/step - loss: 1.3056e-04 - MSE: 1.3056e-04 - val_loss: 4.5532e-05 - val_MSE: 4.5532e-05\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 14s 32ms/step - loss: 1.0485e-04 - MSE: 1.0485e-04 - val_loss: 3.6134e-05 - val_MSE: 3.6134e-05\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 25s 49ms/step - loss: 8.4233e-05 - MSE: 8.4233e-05 - val_loss: 2.7398e-05 - val_MSE: 2.7398e-05\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 12s 27ms/step - loss: 6.7025e-05 - MSE: 6.7025e-05 - val_loss: 2.2376e-05 - val_MSE: 2.2376e-05\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 12s 28ms/step - loss: 5.1657e-05 - MSE: 5.1657e-05 - val_loss: 1.7429e-05 - val_MSE: 1.7429e-05\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 13s 29ms/step - loss: 4.1486e-05 - MSE: 4.1486e-05 - val_loss: 1.5223e-05 - val_MSE: 1.5223e-05\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 14s 32ms/step - loss: 3.2789e-05 - MSE: 3.2789e-05 - val_loss: 1.2857e-05 - val_MSE: 1.2857e-05\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 15s 32ms/step - loss: 2.8208e-05 - MSE: 2.8208e-05 - val_loss: 1.1062e-05 - val_MSE: 1.1062e-05\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 14s 32ms/step - loss: 2.1664e-05 - MSE: 2.1664e-05 - val_loss: 9.0095e-06 - val_MSE: 9.0095e-06\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 14s 32ms/step - loss: 1.9157e-05 - MSE: 1.9157e-05 - val_loss: 8.8500e-06 - val_MSE: 8.8500e-06\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 18s 39ms/step - loss: 1.6359e-05 - MSE: 1.6359e-05 - val_loss: 7.4151e-06 - val_MSE: 7.4151e-06\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 18s 40ms/step - loss: 1.4301e-05 - MSE: 1.4301e-05 - val_loss: 7.6350e-06 - val_MSE: 7.6350e-06\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 18s 40ms/step - loss: 1.2938e-05 - MSE: 1.2938e-05 - val_loss: 6.3443e-06 - val_MSE: 6.3443e-06\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 18s 39ms/step - loss: 1.1538e-05 - MSE: 1.1538e-05 - val_loss: 5.9340e-06 - val_MSE: 5.9340e-06\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 15s 34ms/step - loss: 1.0392e-05 - MSE: 1.0392e-05 - val_loss: 6.7541e-06 - val_MSE: 6.7541e-06\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 15s 33ms/step - loss: 9.7687e-06 - MSE: 9.7687e-06 - val_loss: 5.5745e-06 - val_MSE: 5.5745e-06\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 14s 32ms/step - loss: 9.2523e-06 - MSE: 9.2523e-06 - val_loss: 5.4106e-06 - val_MSE: 5.4106e-06\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 14s 32ms/step - loss: 8.7995e-06 - MSE: 8.7995e-06 - val_loss: 5.1431e-06 - val_MSE: 5.1431e-06\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 15s 33ms/step - loss: 8.3445e-06 - MSE: 8.3445e-06 - val_loss: 5.0695e-06 - val_MSE: 5.0695e-06\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 15s 33ms/step - loss: 8.1259e-06 - MSE: 8.1259e-06 - val_loss: 5.0319e-06 - val_MSE: 5.0319e-06\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 15s 32ms/step - loss: 7.8903e-06 - MSE: 7.8903e-06 - val_loss: 4.9290e-06 - val_MSE: 4.9290e-06\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 15s 32ms/step - loss: 7.7238e-06 - MSE: 7.7238e-06 - val_loss: 5.0387e-06 - val_MSE: 5.0387e-06\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 7.6346e-06 - MSE: 7.6346e-06 - val_loss: 4.9604e-06 - val_MSE: 4.9604e-06\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 18s 39ms/step - loss: 7.5483e-06 - MSE: 7.5483e-06 - val_loss: 4.8555e-06 - val_MSE: 4.8555e-06\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 18s 39ms/step - loss: 7.4228e-06 - MSE: 7.4228e-06 - val_loss: 4.8625e-06 - val_MSE: 4.8625e-06\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 18s 39ms/step - loss: 7.3754e-06 - MSE: 7.3754e-06 - val_loss: 5.0110e-06 - val_MSE: 5.0110e-06\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 18s 40ms/step - loss: 7.2917e-06 - MSE: 7.2917e-06 - val_loss: 4.8660e-06 - val_MSE: 4.8660e-06\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 14s 32ms/step - loss: 7.2895e-06 - MSE: 7.2895e-06 - val_loss: 4.8724e-06 - val_MSE: 4.8724e-06\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 21s 46ms/step - loss: 7.2234e-06 - MSE: 7.2234e-06 - val_loss: 4.8283e-06 - val_MSE: 4.8283e-06\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 15s 33ms/step - loss: 7.2121e-06 - MSE: 7.2121e-06 - val_loss: 4.8284e-06 - val_MSE: 4.8284e-06\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 18s 39ms/step - loss: 7.1799e-06 - MSE: 7.1799e-06 - val_loss: 4.9365e-06 - val_MSE: 4.9365e-06\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 17s 39ms/step - loss: 7.1518e-06 - MSE: 7.1518e-06 - val_loss: 4.9031e-06 - val_MSE: 4.9031e-06\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 15s 32ms/step - loss: 7.1359e-06 - MSE: 7.1359e-06 - val_loss: 4.8695e-06 - val_MSE: 4.8695e-06\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 15s 32ms/step - loss: 7.1293e-06 - MSE: 7.1293e-06 - val_loss: 4.9394e-06 - val_MSE: 4.9394e-06\n",
      "INFO:tensorflow:Assets written to: saved_model/NFE_60_log_s203_sigmoid_4layers\\assets\n",
      "Dataset NFE has been trained and saved.\n",
      "Epoch 1/100\n",
      "348/348 [==============================] - 14s 32ms/step - loss: 0.5164 - MSE: 0.5164 - val_loss: 0.0899 - val_MSE: 0.0899\n",
      "Epoch 2/100\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 0.0900 - MSE: 0.0900 - val_loss: 0.0357 - val_MSE: 0.0357\n",
      "Epoch 3/100\n",
      "348/348 [==============================] - 18s 51ms/step - loss: 0.0404 - MSE: 0.0404 - val_loss: 0.0177 - val_MSE: 0.0177\n",
      "Epoch 4/100\n",
      "348/348 [==============================] - 15s 42ms/step - loss: 0.0216 - MSE: 0.0216 - val_loss: 0.0093 - val_MSE: 0.0093\n",
      "Epoch 5/100\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 0.0129 - MSE: 0.0129 - val_loss: 0.0052 - val_MSE: 0.0052\n",
      "Epoch 6/100\n",
      "348/348 [==============================] - 17s 49ms/step - loss: 0.0082 - MSE: 0.0082 - val_loss: 0.0032 - val_MSE: 0.0032\n",
      "Epoch 7/100\n",
      "348/348 [==============================] - 11s 33ms/step - loss: 0.0053 - MSE: 0.0053 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 8/100\n",
      "348/348 [==============================] - 18s 51ms/step - loss: 0.0037 - MSE: 0.0037 - val_loss: 0.0014 - val_MSE: 0.0014\n",
      "Epoch 9/100\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 0.0026 - MSE: 0.0026 - val_loss: 9.8736e-04 - val_MSE: 9.8736e-04\n",
      "Epoch 10/100\n",
      "348/348 [==============================] - 17s 50ms/step - loss: 0.0019 - MSE: 0.0019 - val_loss: 6.7242e-04 - val_MSE: 6.7242e-04\n",
      "Epoch 11/100\n",
      "348/348 [==============================] - 18s 51ms/step - loss: 0.0014 - MSE: 0.0014 - val_loss: 4.5464e-04 - val_MSE: 4.5464e-04\n",
      "Epoch 12/100\n",
      "348/348 [==============================] - 11s 32ms/step - loss: 0.0010 - MSE: 0.0010 - val_loss: 2.9927e-04 - val_MSE: 2.9927e-04\n",
      "Epoch 13/100\n",
      "348/348 [==============================] - 15s 42ms/step - loss: 7.5115e-04 - MSE: 7.5115e-04 - val_loss: 1.9762e-04 - val_MSE: 1.9762e-04\n",
      "Epoch 14/100\n",
      "348/348 [==============================] - 15s 42ms/step - loss: 5.5822e-04 - MSE: 5.5822e-04 - val_loss: 1.4955e-04 - val_MSE: 1.4955e-04\n",
      "Epoch 15/100\n",
      "348/348 [==============================] - 17s 50ms/step - loss: 4.4021e-04 - MSE: 4.4021e-04 - val_loss: 1.0168e-04 - val_MSE: 1.0168e-04\n",
      "Epoch 16/100\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 3.2651e-04 - MSE: 3.2651e-04 - val_loss: 7.6789e-05 - val_MSE: 7.6789e-05\n",
      "Epoch 17/100\n",
      "348/348 [==============================] - 18s 51ms/step - loss: 2.6427e-04 - MSE: 2.6427e-04 - val_loss: 6.1453e-05 - val_MSE: 6.1453e-05\n",
      "Epoch 18/100\n",
      "348/348 [==============================] - 15s 42ms/step - loss: 1.9895e-04 - MSE: 1.9895e-04 - val_loss: 5.0914e-05 - val_MSE: 5.0914e-05\n",
      "Epoch 19/100\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 1.5827e-04 - MSE: 1.5827e-04 - val_loss: 3.8027e-05 - val_MSE: 3.8027e-05\n",
      "Epoch 20/100\n",
      "348/348 [==============================] - 14s 40ms/step - loss: 1.2606e-04 - MSE: 1.2606e-04 - val_loss: 3.1090e-05 - val_MSE: 3.1090e-05\n",
      "Epoch 21/100\n",
      "348/348 [==============================] - 15s 42ms/step - loss: 1.0399e-04 - MSE: 1.0399e-04 - val_loss: 2.4214e-05 - val_MSE: 2.4214e-05\n",
      "Epoch 22/100\n",
      "348/348 [==============================] - 12s 34ms/step - loss: 8.1739e-05 - MSE: 8.1739e-05 - val_loss: 2.0043e-05 - val_MSE: 2.0043e-05\n",
      "Epoch 23/100\n",
      "348/348 [==============================] - 12s 34ms/step - loss: 6.9656e-05 - MSE: 6.9656e-05 - val_loss: 1.5962e-05 - val_MSE: 1.5962e-05\n",
      "Epoch 24/100\n",
      "348/348 [==============================] - 11s 31ms/step - loss: 5.3369e-05 - MSE: 5.3369e-05 - val_loss: 1.3889e-05 - val_MSE: 1.3889e-05\n",
      "Epoch 25/100\n",
      "348/348 [==============================] - 11s 32ms/step - loss: 4.4927e-05 - MSE: 4.4927e-05 - val_loss: 1.0951e-05 - val_MSE: 1.0951e-05\n",
      "Epoch 26/100\n",
      "348/348 [==============================] - 11s 31ms/step - loss: 3.6410e-05 - MSE: 3.6410e-05 - val_loss: 9.3791e-06 - val_MSE: 9.3791e-06\n",
      "Epoch 27/100\n",
      "348/348 [==============================] - 11s 32ms/step - loss: 3.1684e-05 - MSE: 3.1684e-05 - val_loss: 7.7000e-06 - val_MSE: 7.7000e-06\n",
      "Epoch 28/100\n",
      "348/348 [==============================] - 17s 50ms/step - loss: 2.4743e-05 - MSE: 2.4743e-05 - val_loss: 6.3996e-06 - val_MSE: 6.3996e-06\n",
      "Epoch 29/100\n",
      "348/348 [==============================] - 18s 51ms/step - loss: 2.1756e-05 - MSE: 2.1756e-05 - val_loss: 5.4103e-06 - val_MSE: 5.4103e-06\n",
      "Epoch 30/100\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 1.7790e-05 - MSE: 1.7790e-05 - val_loss: 4.6371e-06 - val_MSE: 4.6371e-06\n",
      "Epoch 31/100\n",
      "348/348 [==============================] - 21s 60ms/step - loss: 1.5932e-05 - MSE: 1.5932e-05 - val_loss: 4.0198e-06 - val_MSE: 4.0198e-06\n",
      "Epoch 32/100\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 1.5165e-05 - MSE: 1.5165e-05 - val_loss: 3.3580e-06 - val_MSE: 3.3580e-06\n",
      "Epoch 33/100\n",
      "348/348 [==============================] - 17s 50ms/step - loss: 1.0794e-05 - MSE: 1.0794e-05 - val_loss: 2.9645e-06 - val_MSE: 2.9645e-06\n",
      "Epoch 34/100\n",
      "348/348 [==============================] - 18s 51ms/step - loss: 9.2117e-06 - MSE: 9.2117e-06 - val_loss: 2.5883e-06 - val_MSE: 2.5883e-06\n",
      "Epoch 35/100\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 7.2364e-06 - MSE: 7.2364e-06 - val_loss: 2.2817e-06 - val_MSE: 2.2817e-06\n",
      "Epoch 36/100\n",
      "348/348 [==============================] - 14s 40ms/step - loss: 6.9029e-06 - MSE: 6.9029e-06 - val_loss: 2.0890e-06 - val_MSE: 2.0890e-06\n",
      "Epoch 37/100\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 5.7424e-06 - MSE: 5.7424e-06 - val_loss: 1.9286e-06 - val_MSE: 1.9286e-06\n",
      "Epoch 38/100\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 5.5609e-06 - MSE: 5.5609e-06 - val_loss: 2.2211e-06 - val_MSE: 2.2211e-06\n",
      "Epoch 39/100\n",
      "348/348 [==============================] - 18s 51ms/step - loss: 4.4867e-06 - MSE: 4.4867e-06 - val_loss: 1.7003e-06 - val_MSE: 1.7003e-06\n",
      "Epoch 40/100\n",
      "348/348 [==============================] - 16s 48ms/step - loss: 3.9343e-06 - MSE: 3.9343e-06 - val_loss: 1.5075e-06 - val_MSE: 1.5075e-06\n",
      "Epoch 41/100\n",
      "348/348 [==============================] - 10s 28ms/step - loss: 3.7344e-06 - MSE: 3.7344e-06 - val_loss: 1.4658e-06 - val_MSE: 1.4658e-06\n",
      "Epoch 42/100\n",
      "348/348 [==============================] - 11s 30ms/step - loss: 3.2850e-06 - MSE: 3.2850e-06 - val_loss: 1.3486e-06 - val_MSE: 1.3486e-06\n",
      "Epoch 43/100\n",
      "348/348 [==============================] - 11s 32ms/step - loss: 2.9219e-06 - MSE: 2.9219e-06 - val_loss: 1.2972e-06 - val_MSE: 1.2972e-06\n",
      "Epoch 44/100\n",
      "348/348 [==============================] - 11s 32ms/step - loss: 2.8431e-06 - MSE: 2.8431e-06 - val_loss: 1.2527e-06 - val_MSE: 1.2527e-06\n",
      "Epoch 45/100\n",
      "348/348 [==============================] - 14s 39ms/step - loss: 2.5559e-06 - MSE: 2.5559e-06 - val_loss: 1.2768e-06 - val_MSE: 1.2768e-06\n",
      "Epoch 46/100\n",
      "348/348 [==============================] - 11s 33ms/step - loss: 2.4226e-06 - MSE: 2.4226e-06 - val_loss: 1.2152e-06 - val_MSE: 1.2152e-06\n",
      "Epoch 47/100\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 2.2821e-06 - MSE: 2.2821e-06 - val_loss: 1.2415e-06 - val_MSE: 1.2415e-06\n",
      "Epoch 48/100\n",
      "348/348 [==============================] - 18s 52ms/step - loss: 2.2344e-06 - MSE: 2.2344e-06 - val_loss: 1.1756e-06 - val_MSE: 1.1756e-06\n",
      "Epoch 49/100\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 2.1351e-06 - MSE: 2.1351e-06 - val_loss: 1.0946e-06 - val_MSE: 1.0946e-06\n",
      "Epoch 50/100\n",
      "348/348 [==============================] - 14s 40ms/step - loss: 2.0120e-06 - MSE: 2.0120e-06 - val_loss: 1.0888e-06 - val_MSE: 1.0888e-06\n",
      "Epoch 51/100\n",
      "348/348 [==============================] - 17s 49ms/step - loss: 1.9726e-06 - MSE: 1.9726e-06 - val_loss: 1.0617e-06 - val_MSE: 1.0617e-06\n",
      "Epoch 52/100\n",
      "348/348 [==============================] - 11s 31ms/step - loss: 1.8935e-06 - MSE: 1.8935e-06 - val_loss: 1.0385e-06 - val_MSE: 1.0385e-06\n",
      "Epoch 53/100\n",
      "348/348 [==============================] - 11s 30ms/step - loss: 1.8810e-06 - MSE: 1.8810e-06 - val_loss: 1.0990e-06 - val_MSE: 1.0990e-06\n",
      "Epoch 54/100\n",
      "348/348 [==============================] - 10s 29ms/step - loss: 1.8965e-06 - MSE: 1.8965e-06 - val_loss: 1.0481e-06 - val_MSE: 1.0481e-06\n",
      "Epoch 55/100\n",
      "348/348 [==============================] - 17s 50ms/step - loss: 1.8069e-06 - MSE: 1.8069e-06 - val_loss: 1.0854e-06 - val_MSE: 1.0854e-06\n",
      "Epoch 56/100\n",
      "348/348 [==============================] - 20s 56ms/step - loss: 1.7166e-06 - MSE: 1.7166e-06 - val_loss: 1.0634e-06 - val_MSE: 1.0634e-06\n",
      "Epoch 57/100\n",
      "348/348 [==============================] - 20s 58ms/step - loss: 1.6888e-06 - MSE: 1.6888e-06 - val_loss: 1.0196e-06 - val_MSE: 1.0196e-06\n",
      "Epoch 58/100\n",
      "348/348 [==============================] - 20s 58ms/step - loss: 1.6932e-06 - MSE: 1.6932e-06 - val_loss: 1.0292e-06 - val_MSE: 1.0292e-06\n",
      "Epoch 59/100\n",
      "348/348 [==============================] - 20s 57ms/step - loss: 1.6854e-06 - MSE: 1.6854e-06 - val_loss: 9.8863e-07 - val_MSE: 9.8863e-07\n",
      "Epoch 60/100\n",
      "348/348 [==============================] - 23s 67ms/step - loss: 1.6497e-06 - MSE: 1.6497e-06 - val_loss: 9.7974e-07 - val_MSE: 9.7974e-07\n",
      "Epoch 61/100\n",
      "348/348 [==============================] - 20s 58ms/step - loss: 1.6386e-06 - MSE: 1.6386e-06 - val_loss: 9.9930e-07 - val_MSE: 9.9930e-07\n",
      "Epoch 62/100\n",
      "348/348 [==============================] - 20s 58ms/step - loss: 1.6174e-06 - MSE: 1.6174e-06 - val_loss: 1.0184e-06 - val_MSE: 1.0184e-06\n",
      "Epoch 63/100\n",
      "348/348 [==============================] - 20s 57ms/step - loss: 1.6273e-06 - MSE: 1.6273e-06 - val_loss: 1.0042e-06 - val_MSE: 1.0042e-06\n",
      "Epoch 64/100\n",
      "348/348 [==============================] - 20s 57ms/step - loss: 1.5947e-06 - MSE: 1.5947e-06 - val_loss: 9.7650e-07 - val_MSE: 9.7650e-07\n",
      "Epoch 65/100\n",
      "348/348 [==============================] - 20s 57ms/step - loss: 1.6002e-06 - MSE: 1.6002e-06 - val_loss: 9.9351e-07 - val_MSE: 9.9351e-07\n",
      "Epoch 66/100\n",
      "348/348 [==============================] - 20s 58ms/step - loss: 1.5952e-06 - MSE: 1.5952e-06 - val_loss: 9.6325e-07 - val_MSE: 9.6325e-07\n",
      "Epoch 67/100\n",
      "348/348 [==============================] - 23s 67ms/step - loss: 1.5733e-06 - MSE: 1.5733e-06 - val_loss: 9.9845e-07 - val_MSE: 9.9845e-07\n",
      "Epoch 68/100\n",
      "348/348 [==============================] - 20s 58ms/step - loss: 1.5808e-06 - MSE: 1.5808e-06 - val_loss: 1.0297e-06 - val_MSE: 1.0297e-06\n",
      "Epoch 69/100\n",
      "348/348 [==============================] - 20s 59ms/step - loss: 1.5681e-06 - MSE: 1.5681e-06 - val_loss: 9.8156e-07 - val_MSE: 9.8156e-07\n",
      "Epoch 70/100\n",
      "348/348 [==============================] - 23s 67ms/step - loss: 1.5771e-06 - MSE: 1.5771e-06 - val_loss: 1.0174e-06 - val_MSE: 1.0174e-06\n",
      "Epoch 71/100\n",
      "348/348 [==============================] - 20s 59ms/step - loss: 1.5728e-06 - MSE: 1.5728e-06 - val_loss: 1.0054e-06 - val_MSE: 1.0054e-06\n",
      "INFO:tensorflow:Assets written to: saved_model/NOC_60_log_s203_sigmoid_4layers\\assets\n",
      "Dataset NOC has been trained and saved.\n",
      "Epoch 1/100\n",
      "530/530 [==============================] - 21s 35ms/step - loss: nan - MSE: nan - val_loss: nan - val_MSE: nan\n",
      "Epoch 2/100\n",
      "530/530 [==============================] - 18s 34ms/step - loss: nan - MSE: nan - val_loss: nan - val_MSE: nan\n",
      "Epoch 3/100\n",
      "530/530 [==============================] - 18s 35ms/step - loss: nan - MSE: nan - val_loss: nan - val_MSE: nan\n",
      "Epoch 4/100\n",
      "530/530 [==============================] - 18s 34ms/step - loss: nan - MSE: nan - val_loss: nan - val_MSE: nan\n",
      "Epoch 5/100\n",
      "530/530 [==============================] - 18s 34ms/step - loss: nan - MSE: nan - val_loss: nan - val_MSE: nan\n",
      "INFO:tensorflow:Assets written to: saved_model/PBR_60_log_s203_sigmoid_4layers\\assets\n",
      "Dataset PBR has been trained and saved.\n",
      "Epoch 1/100\n",
      "561/561 [==============================] - 32s 53ms/step - loss: 3.6836 - MSE: 3.6836 - val_loss: 0.1737 - val_MSE: 0.1737\n",
      "Epoch 2/100\n",
      "561/561 [==============================] - 36s 65ms/step - loss: 0.1832 - MSE: 0.1832 - val_loss: 0.0679 - val_MSE: 0.0679\n",
      "Epoch 3/100\n",
      "561/561 [==============================] - 36s 64ms/step - loss: 0.0769 - MSE: 0.0769 - val_loss: 0.0218 - val_MSE: 0.0218\n",
      "Epoch 4/100\n",
      "561/561 [==============================] - 36s 64ms/step - loss: 0.0295 - MSE: 0.0295 - val_loss: 0.0107 - val_MSE: 0.0107\n",
      "Epoch 5/100\n",
      "561/561 [==============================] - 40s 71ms/step - loss: 0.0154 - MSE: 0.0154 - val_loss: 0.0068 - val_MSE: 0.0068\n",
      "Epoch 6/100\n",
      "561/561 [==============================] - 32s 57ms/step - loss: 0.0100 - MSE: 0.0100 - val_loss: 0.0048 - val_MSE: 0.0048\n",
      "Epoch 7/100\n",
      "561/561 [==============================] - 32s 57ms/step - loss: 0.0071 - MSE: 0.0071 - val_loss: 0.0033 - val_MSE: 0.0033\n",
      "Epoch 8/100\n",
      "561/561 [==============================] - 32s 57ms/step - loss: 0.0050 - MSE: 0.0050 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 9/100\n",
      "561/561 [==============================] - 44s 78ms/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0012 - val_MSE: 0.0012\n",
      "Epoch 10/100\n",
      "561/561 [==============================] - 47s 83ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 7.0717e-04 - val_MSE: 7.0717e-04\n",
      "Epoch 11/100\n",
      "561/561 [==============================] - 47s 84ms/step - loss: 0.0015 - MSE: 0.0015 - val_loss: 4.2093e-04 - val_MSE: 4.2093e-04\n",
      "Epoch 12/100\n",
      "561/561 [==============================] - 39s 70ms/step - loss: 9.5233e-04 - MSE: 9.5233e-04 - val_loss: 2.6097e-04 - val_MSE: 2.6097e-04\n",
      "Epoch 13/100\n",
      "561/561 [==============================] - 32s 57ms/step - loss: 6.2964e-04 - MSE: 6.2964e-04 - val_loss: 1.7360e-04 - val_MSE: 1.7360e-04\n",
      "Epoch 14/100\n",
      "561/561 [==============================] - 32s 57ms/step - loss: 4.3131e-04 - MSE: 4.3131e-04 - val_loss: 1.2112e-04 - val_MSE: 1.2112e-04\n",
      "Epoch 15/100\n",
      "561/561 [==============================] - 23s 41ms/step - loss: 2.9325e-04 - MSE: 2.9325e-04 - val_loss: 9.2156e-05 - val_MSE: 9.2156e-05\n",
      "Epoch 16/100\n",
      "561/561 [==============================] - 17s 30ms/step - loss: 2.2331e-04 - MSE: 2.2331e-04 - val_loss: 7.2293e-05 - val_MSE: 7.2293e-05\n",
      "Epoch 17/100\n",
      "561/561 [==============================] - 14s 24ms/step - loss: 1.6642e-04 - MSE: 1.6642e-04 - val_loss: 5.5193e-05 - val_MSE: 5.5193e-05\n",
      "Epoch 18/100\n",
      "561/561 [==============================] - 16s 28ms/step - loss: 1.2277e-04 - MSE: 1.2277e-04 - val_loss: 4.2130e-05 - val_MSE: 4.2130e-05\n",
      "Epoch 19/100\n",
      "561/561 [==============================] - 30s 53ms/step - loss: 9.0456e-05 - MSE: 9.0456e-05 - val_loss: 3.2310e-05 - val_MSE: 3.2310e-05\n",
      "Epoch 20/100\n",
      "561/561 [==============================] - 25s 45ms/step - loss: 6.7418e-05 - MSE: 6.7418e-05 - val_loss: 2.2258e-05 - val_MSE: 2.2258e-05\n",
      "Epoch 21/100\n",
      "561/561 [==============================] - 13s 24ms/step - loss: 4.9508e-05 - MSE: 4.9508e-05 - val_loss: 1.6970e-05 - val_MSE: 1.6970e-05\n",
      "Epoch 22/100\n",
      "561/561 [==============================] - 25s 45ms/step - loss: 3.4523e-05 - MSE: 3.4523e-05 - val_loss: 1.0611e-05 - val_MSE: 1.0611e-05\n",
      "Epoch 23/100\n",
      "561/561 [==============================] - 13s 24ms/step - loss: 2.6319e-05 - MSE: 2.6319e-05 - val_loss: 7.8435e-06 - val_MSE: 7.8435e-06\n",
      "Epoch 24/100\n",
      "561/561 [==============================] - 13s 24ms/step - loss: 1.8881e-05 - MSE: 1.8881e-05 - val_loss: 5.9480e-06 - val_MSE: 5.9480e-06\n",
      "Epoch 25/100\n",
      "561/561 [==============================] - 16s 28ms/step - loss: 1.4179e-05 - MSE: 1.4179e-05 - val_loss: 4.5286e-06 - val_MSE: 4.5286e-06\n",
      "Epoch 26/100\n",
      "561/561 [==============================] - 13s 24ms/step - loss: 1.1086e-05 - MSE: 1.1086e-05 - val_loss: 3.8094e-06 - val_MSE: 3.8094e-06\n",
      "Epoch 27/100\n",
      "561/561 [==============================] - 16s 28ms/step - loss: 8.8037e-06 - MSE: 8.8037e-06 - val_loss: 3.3405e-06 - val_MSE: 3.3405e-06\n",
      "Epoch 28/100\n",
      "561/561 [==============================] - 13s 24ms/step - loss: 7.1721e-06 - MSE: 7.1721e-06 - val_loss: 3.1786e-06 - val_MSE: 3.1786e-06\n",
      "Epoch 29/100\n",
      "561/561 [==============================] - 16s 28ms/step - loss: 6.6677e-06 - MSE: 6.6677e-06 - val_loss: 2.8299e-06 - val_MSE: 2.8299e-06\n",
      "Epoch 30/100\n",
      "561/561 [==============================] - 13s 24ms/step - loss: 5.3360e-06 - MSE: 5.3360e-06 - val_loss: 2.7933e-06 - val_MSE: 2.7933e-06\n",
      "Epoch 31/100\n",
      "561/561 [==============================] - 16s 28ms/step - loss: 4.9881e-06 - MSE: 4.9881e-06 - val_loss: 2.6489e-06 - val_MSE: 2.6489e-06\n",
      "Epoch 32/100\n",
      "561/561 [==============================] - 13s 24ms/step - loss: 4.4878e-06 - MSE: 4.4878e-06 - val_loss: 2.5642e-06 - val_MSE: 2.5642e-06\n",
      "Epoch 33/100\n",
      "561/561 [==============================] - 13s 24ms/step - loss: 4.1665e-06 - MSE: 4.1665e-06 - val_loss: 2.4866e-06 - val_MSE: 2.4866e-06\n",
      "Epoch 34/100\n",
      "561/561 [==============================] - 16s 29ms/step - loss: 3.9808e-06 - MSE: 3.9808e-06 - val_loss: 2.6125e-06 - val_MSE: 2.6125e-06\n",
      "Epoch 35/100\n",
      "561/561 [==============================] - 16s 28ms/step - loss: 3.8561e-06 - MSE: 3.8561e-06 - val_loss: 2.5608e-06 - val_MSE: 2.5608e-06\n",
      "Epoch 36/100\n",
      "561/561 [==============================] - 13s 24ms/step - loss: 3.5861e-06 - MSE: 3.5861e-06 - val_loss: 2.4061e-06 - val_MSE: 2.4061e-06\n",
      "Epoch 37/100\n",
      "561/561 [==============================] - 16s 28ms/step - loss: 3.5937e-06 - MSE: 3.5937e-06 - val_loss: 2.4482e-06 - val_MSE: 2.4482e-06\n",
      "Epoch 38/100\n",
      "561/561 [==============================] - 13s 24ms/step - loss: 3.4696e-06 - MSE: 3.4696e-06 - val_loss: 2.6187e-06 - val_MSE: 2.6187e-06\n",
      "Epoch 39/100\n",
      "561/561 [==============================] - 13s 24ms/step - loss: 3.4502e-06 - MSE: 3.4502e-06 - val_loss: 2.3863e-06 - val_MSE: 2.3863e-06\n",
      "Epoch 40/100\n",
      "561/561 [==============================] - 9s 12ms/step - loss: 3.4019e-06 - MSE: 3.4019e-06 - val_loss: 2.3651e-06 - val_MSE: 2.3651e-06\n",
      "Epoch 41/100\n",
      "561/561 [==============================] - 7s 12ms/step - loss: 3.3800e-06 - MSE: 3.3800e-06 - val_loss: 2.3574e-06 - val_MSE: 2.3574e-06\n",
      "Epoch 42/100\n",
      "561/561 [==============================] - 9s 16ms/step - loss: 3.3148e-06 - MSE: 3.3148e-06 - val_loss: 2.3717e-06 - val_MSE: 2.3717e-06\n",
      "Epoch 43/100\n",
      "561/561 [==============================] - 13s 24ms/step - loss: 3.2987e-06 - MSE: 3.2987e-06 - val_loss: 2.3888e-06 - val_MSE: 2.3888e-06\n",
      "Epoch 44/100\n",
      "561/561 [==============================] - 16s 28ms/step - loss: 3.2810e-06 - MSE: 3.2810e-06 - val_loss: 2.4182e-06 - val_MSE: 2.4182e-06\n",
      "Epoch 45/100\n",
      "561/561 [==============================] - 13s 24ms/step - loss: 3.3339e-06 - MSE: 3.3339e-06 - val_loss: 2.4571e-06 - val_MSE: 2.4571e-06\n",
      "Epoch 46/100\n",
      "561/561 [==============================] - 13s 24ms/step - loss: 3.3106e-06 - MSE: 3.3106e-06 - val_loss: 2.4412e-06 - val_MSE: 2.4412e-06\n",
      "INFO:tensorflow:Assets written to: saved_model/STLD_60_log_s203_sigmoid_4layers\\assets\n",
      "Dataset STLD has been trained and saved.\n"
     ]
    }
   ],
   "source": [
    "STRIDE = (20, 3)    # stride for feature block\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "CALLBACKS = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
    "\n",
    "all_loss = list()\n",
    "for name, train_dt, valid_dt in load_dataset(TRAIN_DIR, VALID_DIR):\n",
    "    feature = alphanet_feature_Block(STRIDE)\n",
    "    model = build_AlphaNet(\n",
    "        feature, \n",
    "        input_shape=tuple(train_dt.element_spec[0].shape), \n",
    "        output_shape=tuple(train_dt.element_spec[1].shape)[0]\n",
    "    )\n",
    "    train_dt = train_dt.batch(BATCH_SIZE)\n",
    "    valid_dt = valid_dt.batch(BATCH_SIZE)\n",
    "    history = model.fit(\n",
    "        train_dt,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=valid_dt,\n",
    "        callbacks=CALLBACKS,\n",
    "        shuffle=True,\n",
    "        use_multiprocessing=True,\n",
    "        workers=10\n",
    "    )\n",
    "    all_loss.append({\n",
    "        \"stock\": name,\n",
    "        \"epoch\": len(history.history[\"loss\"]),\n",
    "        \"train_loss\": history.history[\"loss\"][-1],\n",
    "        \"valid_loss\": history.history[\"val_loss\"][-1]\n",
    "    })\n",
    "    model.save(f\"{SAVE_DIR}/{name}_60_log_s203_sigmoid_4layers\")\n",
    "    print(f\"Dataset {name} has been trained and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4Bm_yzw7pVDB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1666277042056,
     "user": {
      "displayName": "Junhao Huang",
      "userId": "04740354632925395357"
     },
     "user_tz": -480
    },
    "id": "4Bm_yzw7pVDB",
    "outputId": "e44cce44-1361-4ec0-8a83-b4814d78e8cc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  stock  epoch  train_loss    valid_loss\n0   LMT     57    0.000001  8.572648e-07\n1   BAH     61    0.000001  9.356373e-07\n2   NOC     71    0.000002  1.005361e-06\n3   HII    100    0.000002  1.981150e-06\n4  STLD     46    0.000003  2.441190e-06\n5   MLI     92    0.000004  2.856066e-06\n6    AR     59    0.000006  4.604302e-06\n7   NFE     53    0.000007  4.939388e-06\n8   FTI      5         NaN           NaN\n9   PBR      5         NaN           NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stock</th>\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LMT</td>\n      <td>57</td>\n      <td>0.000001</td>\n      <td>8.572648e-07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BAH</td>\n      <td>61</td>\n      <td>0.000001</td>\n      <td>9.356373e-07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NOC</td>\n      <td>71</td>\n      <td>0.000002</td>\n      <td>1.005361e-06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HII</td>\n      <td>100</td>\n      <td>0.000002</td>\n      <td>1.981150e-06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>STLD</td>\n      <td>46</td>\n      <td>0.000003</td>\n      <td>2.441190e-06</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>MLI</td>\n      <td>92</td>\n      <td>0.000004</td>\n      <td>2.856066e-06</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>AR</td>\n      <td>59</td>\n      <td>0.000006</td>\n      <td>4.604302e-06</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NFE</td>\n      <td>53</td>\n      <td>0.000007</td>\n      <td>4.939388e-06</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>FTI</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>PBR</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame(all_loss).sort_values(\"valid_loss\").reset_index(drop=True)\n",
    "temp.to_csv(f\"{OUTPUT_DIR}/all_loss_60_log_s203_sigmoid_4layers.csv\")\n",
    "temp"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "31b9f103-0a81-4cc1-8e8c-226d40f546cf",
    "98797082-b05f-4949-97e3-02b52bb03d79",
    "cyfLh4DI-5it"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "99ea4bddf300909f6d049ff7715ecae0b1516d9d48b79ec655d91803e59750be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}